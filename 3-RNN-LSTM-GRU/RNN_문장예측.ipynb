{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qh0h2sFFdKCk"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "# âœ… ìƒ˜í”Œ ë°ì´í„°ì…‹ (ë¬¸ì¥ ì˜ˆì œ)\n",
    "corpus = [\n",
    "   \"ë‚˜ëŠ” ë„ˆë¥¼ ì‚¬ë‘í•´\",\n",
    "    \"ë‚˜ëŠ” ì½”ë”©ì„ ì¢‹ì•„í•´\",\n",
    "    \"ë„ˆëŠ” ë‚˜ë¥¼ ì¢‹ì•„í•´\",\n",
    "    \"ë„ˆëŠ” íŒŒì´ì¬ì„ ê³µë¶€í•´\",\n",
    "    \"ìš°ë¦¬ëŠ” ì¸ê³µì§€ëŠ¥ì„ ì—°êµ¬í•´\",\n",
    "    \"ë”¥ëŸ¬ë‹ì€ ì¬ë¯¸ìˆì–´\",\n",
    "    \"íŒŒì´ì¬ì€ ê°•ë ¥í•´\",\n",
    "    \"ë‚˜ëŠ” ìì—°ì–´ì²˜ë¦¬ë¥¼ ê³µë¶€í•´\",\n",
    "]\n",
    "\n",
    "# âœ… ë‹¨ì–´ ì‚¬ì „ ë§Œë“¤ê¸° (Tokenization)\n",
    "word_list = list(set(\" \".join(corpus).split()))\n",
    "word_dict = {w: i for i, w in enumerate(word_list)}\n",
    "idx_dict = {i: w for w, i in word_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# âœ… ë°ì´í„°ì…‹ ë³€í™˜\n",
    "def make_data(corpus):\n",
    "    inputs, targets = [], []\n",
    "    for sentence in corpus:\n",
    "        words = sentence.split()\n",
    "        for i in range(len(words) - 1):  # \"I love\" -> \"you\"\n",
    "            x = [word_dict[w] for w in words[:i+1]]\n",
    "            y = word_dict[words[i+1]]\n",
    "            inputs.append(x)\n",
    "            targets.append(y)\n",
    "\n",
    "    return inputs, targets\n",
    "\n",
    "inputs, targets = make_data(corpus)\n",
    "\n",
    "# âœ… íŒ¨ë”© ì¶”ê°€ (ë¬¸ì¥ ê¸¸ì´ë¥¼ ë§ì¶¤)\n",
    "max_len = max(len(seq) for seq in inputs)\n",
    "inputs_padded = [seq + [0] * (max_len - len(seq)) for seq in inputs]\n",
    "targets = torch.tensor(targets, dtype=torch.long)\n",
    "\n",
    "# âœ… ë°ì´í„°ì…‹ ë° DataLoader ìƒì„±\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, inputs, targets):\n",
    "        self.inputs = torch.tensor(inputs, dtype=torch.long)\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs[idx], self.targets[idx]\n",
    "\n",
    "dataset = TextDataset(inputs_padded, targets)\n",
    "train_loader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "vocab_size = len(word_dict)  # ë‹¨ì–´ ê°œìˆ˜\n",
    "embed_size = 10  # ì„ë² ë”© ì°¨ì›\n",
    "hidden_size = 16  # RNN ì€ë‹‰ì¸µ í¬ê¸°\n",
    "num_classes = len(word_dict)  # ì˜ˆì¸¡í•  ë‹¨ì–´ ê°œìˆ˜"
   ],
   "metadata": {
    "id": "vBA5wXf1dO66"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class RNNTextModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_classes):\n",
    "        super(RNNTextModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)  # ë‹¨ì–´ ì„ë² ë”©\n",
    "        self.rnn = nn.RNN(embed_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        out, _ = self.rnn(x)\n",
    "        out = self.fc(out[:, -1, :])  # ë§ˆì§€ë§‰ ì‹œì ì˜ RNN ì¶œë ¥ì„ ì‚¬ìš©\n",
    "        return out\n",
    "\n",
    "# âœ… ëª¨ë¸ ìƒì„±\n",
    "model = RNNTextModel(vocab_size, embed_size, hidden_size, num_classes)\n",
    "\n",
    "# âœ… GPU ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ ì´ë™\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# âœ… ì†ì‹¤ í•¨ìˆ˜ ë° ìµœì í™” í•¨ìˆ˜ ì„¤ì •\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n"
   ],
   "metadata": {
    "id": "JA-ya6xFdO9i"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "num_epochs = 100\n",
    "print(\"ğŸš€ RNN ëª¨ë¸ í•™ìŠµ ì‹œì‘...\")\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}\")\n",
    "\n",
    "# âœ… ëª¨ë¸ ì €ì¥\n",
    "model_path = \"/content/drive/MyDrive/busanit501-1234/rnn_korean_model.pth\"\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"âœ… í•™ìŠµëœ ëª¨ë¸ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {model_path}\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mViO4JjjdPAC",
    "outputId": "cfc00e64-c5e6-4ff5-915d-1db18922d64d"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ğŸš€ RNN ëª¨ë¸ í•™ìŠµ ì‹œì‘...\n",
      "Epoch [10/100], Loss: 0.8826\n",
      "Epoch [20/100], Loss: 0.4593\n",
      "Epoch [30/100], Loss: 0.4012\n",
      "Epoch [40/100], Loss: 0.3711\n",
      "Epoch [50/100], Loss: 0.3696\n",
      "Epoch [60/100], Loss: 0.3681\n",
      "Epoch [70/100], Loss: 0.3545\n",
      "Epoch [80/100], Loss: 0.3639\n",
      "Epoch [90/100], Loss: 0.3621\n",
      "Epoch [100/100], Loss: 0.3470\n",
      "âœ… í•™ìŠµëœ ëª¨ë¸ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: /content/drive/MyDrive/busanit501-1234/rnn_korean_model.pth\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# âœ… ì €ì¥ëœ RNN ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "def load_model(model_path, vocab_size, embed_size, hidden_size, num_classes):\n",
    "    model = RNNTextModel(vocab_size, embed_size, hidden_size, num_classes)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=torch.device(\"cpu\")))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# âœ… ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "loaded_model = load_model(model_path, vocab_size, embed_size, hidden_size, num_classes)\n",
    "print(\"âœ… ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™€ì¡ŒìŠµë‹ˆë‹¤!\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hVyedZkzdPCq",
    "outputId": "abb02bf9-9de6-4e5d-98e2-02a4396593d9"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "âœ… ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™€ì¡ŒìŠµë‹ˆë‹¤!\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def predict_next_word(model, sentence):\n",
    "    \"\"\"\n",
    "    ì €ì¥ëœ RNN ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì£¼ì–´ì§„ ë¬¸ì¥ì˜ ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ëŠ” í•¨ìˆ˜.\n",
    "    \"\"\"\n",
    "    # âœ… ì…ë ¥ ë¬¸ì¥ì„ ì •ìˆ˜ ì¸ì½”ë”©\n",
    "    words = sentence.split()\n",
    "    input_seq = [word_dict[w] for w in words if w in word_dict]\n",
    "\n",
    "    # âœ… íŒ¨ë”© ì¶”ê°€ (ê¸¸ì´ë¥¼ ë§ì¶”ê¸° ìœ„í•´)\n",
    "    input_padded = input_seq + [0] * (max_len - len(input_seq))\n",
    "    input_tensor = torch.tensor([input_padded], dtype=torch.long)\n",
    "\n",
    "    # âœ… ëª¨ë¸ ì˜ˆì¸¡\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        probabilities = F.softmax(output[0], dim=0)\n",
    "        predicted_idx = torch.argmax(probabilities).item()\n",
    "        confidence = probabilities[predicted_idx].item()\n",
    "\n",
    "    predicted_word = idx_dict[predicted_idx]\n",
    "\n",
    "    print(f\"ğŸ” ì…ë ¥ ë¬¸ì¥: '{sentence}'\")\n",
    "    print(f\"ğŸ“Š ì˜ˆì¸¡ëœ ë‹¨ì–´: '{predicted_word}'\")\n",
    "    print(f\"âœ… ì˜ˆì¸¡ í™•ë¥ : {confidence * 100:.2f}%\")\n",
    "\n",
    "# ğŸ† ìƒ˜í”Œ ë¬¸ì¥ ì˜ˆì¸¡ ì‹¤í–‰\n",
    "sample_sentence = \"ë‚˜ëŠ” ë„ˆë¥¼\"\n",
    "predict_next_word(loaded_model, sample_sentence)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-uMGRfO3dPFK",
    "outputId": "1d892e93-c738-4f47-9999-6928b3b90857"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ğŸ” ì…ë ¥ ë¬¸ì¥: 'ë‚˜ëŠ” ë„ˆë¥¼'\n",
      "ğŸ“Š ì˜ˆì¸¡ëœ ë‹¨ì–´: 'ì‚¬ë‘í•´'\n",
      "âœ… ì˜ˆì¸¡ í™•ë¥ : 99.53%\n"
     ]
    }
   ]
  }
 ]
}
