2-0-PyTorchì˜ ëœë¤ í…ì„œ ìƒì„± í•¨ìˆ˜ ì†Œê°œ ë° ì˜ˆì œ
2-1-ì¸í”Œë ˆì´ìŠ¤(In-Place) ì—°ì‚°ì´ë€
2-2-PyTorch view() í•¨ìˆ˜
2-3-squeeze() vs unsqueeze() í•¨ìˆ˜ ì°¨ì´ì 
2-3-2-torch.cat([x.unsqueeze(0), y.unsqueeze(0)], dim=0) ì˜ˆì œ
2-4-2-í…ì„œ(Tensor) í¬ê¸° ë° ìš”ì†Œ ë³€í™” ê°œë… ì„¤ëª…
2-4-3-ì…ë ¥ ë°ì´í„° shape ë° ì¶œë ¥ ë°ì´í„° shape ë¶„ì„
2-4-4-3ì°¨ì› í…ì„œ(3D Tensor)ì—ì„œ ì¸ë±ìŠ¤ ë³„ ìœ„ì¹˜ ì´í•´
2-5-split() vs chunk() ì°¨ì´ì 
2-6-torch.index_select() í•¨ìˆ˜
2-7-torch.cat() (Concatenate) í•¨ìˆ˜
2-8-torch.stack() í•¨ìˆ˜
2-9-expand() ì˜ˆì œ
2-10-torch.randperm() ì˜ˆì œ
2-11-torch.argmax(dim=n) ì˜ˆì œ
2-12-torch.topk() ì˜ˆì œ
2-13-masked_fill() ì˜ˆì œ
2-14-ones(), zeros(), ones_like(), zeros_like() ì˜ˆì œ

=============================================================================
2-0-PyTorchì˜ ëœë¤ í…ì„œ ìƒì„± í•¨ìˆ˜ ì†Œê°œ ë° ì˜ˆì œ

PyTorchì—ì„œëŠ” ë‹¤ì–‘í•œ ëœë¤(Random) í•¨ìˆ˜ë¥¼ ì œê³µí•˜ë©°,
ì£¼ë¡œ ë¬´ì‘ìœ„ ë°ì´í„° ìƒ˜í”Œë§, ì´ˆê¸° ê°€ì¤‘ì¹˜ ì„¤ì •,
ë°ì´í„° ë…¸ì´ì¦ˆ ì¶”ê°€ ë“±ì— í™œìš©ë©ë‹ˆë‹¤.

1. torch.randn()

âœ… í‘œì¤€ ì •ê·œ ë¶„í¬(Standard Normal Distribution)ì—ì„œ ëœë¤ ìƒ˜í”Œ ìƒì„±

í‰ê· (ğœ‡) = 0, í‘œì¤€í¸ì°¨(ğœ) = 1 ì¸ ì •ê·œ ë¶„í¬(ê°€ìš°ì‹œì•ˆ ë¶„í¬)ì—ì„œ ìƒ˜í”Œë§

ì…ë ¥ìœ¼ë¡œ í…ì„œì˜ í¬ê¸°(shape)ë¥¼ ì§€ì •í•˜ë©´ í•´ë‹¹ í¬ê¸°ì˜ ëœë¤ í…ì„œ ìƒì„±

import torch

# 3Ã—3 ì •ê·œ ë¶„í¬ í…ì„œ ìƒì„± (í‰ê·  0, í‘œì¤€í¸ì°¨ 1)
tensor = torch.randn(3, 3)
print(tensor)

ğŸ“Œ ì˜ˆì œ ì¶œë ¥

tensor([[ 0.2367, -1.2476,  0.8234],
        [-0.9871,  0.3215, -1.7642],
        [ 0.5923, -0.0032,  0.8493]])


2. torch.rand()

âœ… ê· ë“± ë¶„í¬(Uniform Distribution)ì—ì„œ ëœë¤ ìƒ˜í”Œ ìƒì„±
ë²”ìœ„: [0, 1] ì‚¬ì´ì˜ ê· ë“±í•œ ë¶„í¬ì—ì„œ ìƒ˜í”Œë§

tensor = torch.rand(3, 3)  # 0~1 ì‚¬ì´ ëœë¤ ê°’

print(tensor)
ğŸ“Œ ì˜ˆì œ ì¶œë ¥

tensor([[0.6234, 0.1372, 0.8924],
        [0.2145, 0.9871, 0.4532],
        [0.5623, 0.0014, 0.7143]])


3. torch.randint()

âœ… ì§€ì •í•œ ì •ìˆ˜ ë²”ìœ„ì—ì„œ ëœë¤ ì •ìˆ˜ ìƒ˜í”Œ ìƒì„±
low (ìµœì†Œê°’)ê³¼ high (ìµœëŒ€ê°’)ì„ ì§€ì •í•˜ì—¬ ì •ìˆ˜ ê°’ì„ ë¬´ì‘ìœ„ ìƒì„±

tensor = torch.randint(0, 10, (3, 3))  # 0~9 ì‚¬ì´ ì •ìˆ˜ ìƒì„±

print(tensor)

ğŸ“Œ ì˜ˆì œ ì¶œë ¥

tensor([[5, 2, 8],
        [1, 7, 3],
        [0, 4, 6]])


4. torch.randint_like()

âœ… ê¸°ì¡´ í…ì„œì™€ ê°™ì€ shapeì˜ ëœë¤ ì •ìˆ˜ í…ì„œ ìƒì„±

x = torch.ones(3, 3)  # ê¸°ì¡´ í…ì„œ

rand_tensor = torch.randint_like(x, 0, 10)  # ê¸°ì¡´ í¬ê¸° ìœ ì§€, 0~9 ì •ìˆ˜ ìƒ˜í”Œë§

print(rand_tensor)


5. torch.normal()

âœ… ì‚¬ìš©ìê°€ ì§€ì •í•œ í‰ê· (ğœ‡)ê³¼ í‘œì¤€í¸ì°¨(ğœ)ë¡œ ì •ê·œ ë¶„í¬ ìƒ˜í”Œ ìƒì„±

mean = torch.tensor([0.0, 2.0, 4.0])  # í‰ê· 
std = torch.tensor([1.0, 0.5, 0.1])  # í‘œì¤€í¸ì°¨

tensor = torch.normal(mean, std)  # ê° ìš”ì†Œë³„ë¡œ ì§€ì •í•œ í‰ê· ê³¼ í‘œì¤€í¸ì°¨ ì ìš©

print(tensor)

ğŸ“Œ ì˜ˆì œ ì¶œë ¥

tensor([-0.1032,  2.3213,  4.0734])

6. torch.randperm()

âœ… ì§€ì •ëœ ë²”ìœ„ ë‚´ì—ì„œ ì •ìˆ˜ë¥¼ ë¬´ì‘ìœ„ë¡œ ì„ìŒ (ìˆœì—´ ìƒì„±)

tensor = torch.randperm(10)  # 0~9 ì •ìˆ˜ë¥¼ ë¬´ì‘ìœ„ ì„ê¸°
print(tensor)

ğŸ“Œ ì˜ˆì œ ì¶œë ¥

tensor([3, 7, 5, 1, 9, 0, 6, 8, 4, 2])

â¡ ë°ì´í„°ë¥¼ ë¬´ì‘ìœ„ë¡œ ì„ì„ ë•Œ ìœ ìš©

7. torch.bernoulli()

âœ… ë² ë¥´ëˆ„ì´ ë¶„í¬(Bernoulli Distribution)ì—ì„œ ìƒ˜í”Œë§ (0 ë˜ëŠ” 1)

ì…ë ¥ í…ì„œì˜ ê° ìš”ì†Œë¥¼ í™•ë¥ ë¡œ ì‚¬ìš©í•˜ì—¬ 0 ë˜ëŠ” 1ì„ ë°˜í™˜

probs = torch.tensor([0.2, 0.8, 0.5, 0.9])  # 0~1 ì‚¬ì´ í™•ë¥ ê°’

tensor = torch.bernoulli(probs)  # ê° í™•ë¥ ì— ë”°ë¼ 0 ë˜ëŠ” 1 ìƒì„±

print(tensor)

ğŸ“Œ ì˜ˆì œ ì¶œë ¥

tensor([0., 1., 0., 1.])


8. torch.multinomial()

âœ… ë‹¤í•­ ë¶„í¬(Multinomial Distribution)ì—ì„œ ìƒ˜í”Œë§

probs í…ì„œê°€ ì£¼ì–´ì¡Œì„ ë•Œ, num_samples ê°œìˆ˜ë§Œí¼ ëœë¤ ìƒ˜í”Œì„ ì¶”ì¶œ

probs = torch.tensor([0.1, 0.2, 0.3, 0.4])  # ê° ìš”ì†Œì˜ ì„ íƒ í™•ë¥ 
tensor = torch.multinomial(probs, 2, replacement=True)  # 2ê°œ ì„ íƒ (ë³µì› ì¶”ì¶œ)
print(tensor)

ğŸ“Œ ì˜ˆì œ ì¶œë ¥

tensor([3, 1])


9. torch.seed()

âœ… ëœë¤ ì‹œë“œ ê³ ì •

ì‹¤í—˜ì„ ì¬í˜„ ê°€ëŠ¥í•˜ë„ë¡ í•˜ê¸° ìœ„í•´ ì‚¬ìš©

torch.manual_seed(42)  # ì‹œë“œ ê³ ì •
print(torch.rand(3, 3))  # ë™ì¼í•œ ë‚œìˆ˜ ìƒì„±

ğŸ“Œ ì‹¤í–‰ ê²°ê³¼

tensor([[0.8823, 0.9150, 0.3829],
        [0.9593, 0.3904, 0.6009],
        [0.2566, 0.7936, 0.9408]])

â¡ ë‹¤ì‹œ ì‹¤í–‰í•´ë„ ë™ì¼í•œ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŒ!

=============================================================================
2-1-ì¸í”Œë ˆì´ìŠ¤(In-Place) ì—°ì‚°ì´ë€

ì¸í”Œë ˆì´ìŠ¤(In-Place) ì—°ì‚°ì€ ê¸°ì¡´ì˜ **í…ì„œë¥¼ ë³€ê²½(ë®ì–´ì“°ê¸°)**í•˜ëŠ” ì—°ì‚°ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.

ì¦‰, ìƒˆë¡œìš´ í…ì„œë¥¼ ìƒì„±í•˜ì§€ ì•Šê³ , ê¸°ì¡´ í…ì„œì˜ ë©”ëª¨ë¦¬ë¥¼ ì§ì ‘ ìˆ˜ì •í•˜ëŠ” ì—°ì‚° ë°©ì‹ì…ë‹ˆë‹¤.

PyTorchì—ì„œëŠ” ì¸í”Œë ˆì´ìŠ¤ ì—°ì‚°ì˜ ê²½ìš° ì—°ì‚°ì ì´ë¦„ ëì— _(ì–¸ë”ìŠ¤ì½”ì–´)ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.

ì˜ˆë¥¼ ë“¤ì–´, tensor.add_()ì™€ ê°™ì€ ì—°ì‚°ì´ ì¸í”Œë ˆì´ìŠ¤ ì—°ì‚°ì…ë‹ˆë‹¤.


import torch

# ê¸°ì¡´ í…ì„œ
x = torch.tensor([1, 2, 3], dtype=torch.float32)

# ì¼ë°˜ ì—°ì‚° (ìƒˆë¡œìš´ í…ì„œ ë°˜í™˜)
y = x + 10
print("x (ì›ë³¸):", x)  # ì›ë³¸ í…ì„œ ë³€ê²½ ì—†ìŒ
print("y (ìƒˆë¡œìš´ í…ì„œ):", y)  # ìƒˆë¡œìš´ í…ì„œ ìƒì„±ë¨

# ì¸í”Œë ˆì´ìŠ¤ ì—°ì‚°
x.add_(10)
print("x (ì¸í”Œë ˆì´ìŠ¤ ì—°ì‚° í›„):", x)  # ê¸°ì¡´ í…ì„œê°€ ë³€ê²½ë¨

ğŸ“Œ ì‹¤í–‰ ê²°ê³¼


x (ì›ë³¸): tensor([1., 2., 3.])
y (ìƒˆë¡œìš´ í…ì„œ): tensor([11., 12., 13.])
x (ì¸í”Œë ˆì´ìŠ¤ ì—°ì‚° í›„): tensor([11., 12., 13.])

âœ… ì¼ë°˜ ì—°ì‚°(x + 10)ì€ ê¸°ì¡´ í…ì„œ xë¥¼ ë³€ê²½í•˜ì§€ ì•Šê³  ìƒˆë¡œìš´ í…ì„œ yë¥¼ ë°˜í™˜
âœ… ì¸í”Œë ˆì´ìŠ¤ ì—°ì‚°(x.add_(10))ì€ ê¸°ì¡´ í…ì„œ xë¥¼ ì§ì ‘ ë³€ê²½

2. ì£¼ìš” ì¸í”Œë ˆì´ìŠ¤ ì—°ì‚°
ì—°ì‚°	ì¼ë°˜ ì—°ì‚°	ì¸í”Œë ˆì´ìŠ¤ ì—°ì‚°
ë§ì…ˆ	x = x + 5	x.add_(5)
ëº„ì…ˆ	x = x - 3	x.sub_(3)
ê³±ì…ˆ	x = x * 2	x.mul_(2)
ë‚˜ëˆ—ì…ˆ	x = x / 4	x.div_(4)
ì§€ìˆ˜ í•¨ìˆ˜	x = x.exp()	x.exp_()
ì •ê·œí™”	x = x.sqrt()	x.sqrt_()

3. ì¸í”Œë ˆì´ìŠ¤ ì—°ì‚°ì˜ ì¥ì 

âœ… ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê°ì†Œ

x = torch.randn(1000, 1000)

# ì¼ë°˜ ì—°ì‚° (ìƒˆë¡œìš´ ë©”ëª¨ë¦¬ í• ë‹¹)
y = x + 10  # ìƒˆë¡œìš´ í…ì„œê°€ ìƒì„±ë¨

# ì¸í”Œë ˆì´ìŠ¤ ì—°ì‚° (ë©”ëª¨ë¦¬ ì ˆì•½)
x.add_(10)  # ê¸°ì¡´ í…ì„œ xê°€ ì§ì ‘ ë³€ê²½ë¨

â¡ ì¸í”Œë ˆì´ìŠ¤ ì—°ì‚°ì„ ì‚¬ìš©í•˜ë©´ ìƒˆë¡œìš´ í…ì„œë¥¼ ìƒì„±í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ì¤„ì–´ë“¦

4. ì¸í”Œë ˆì´ìŠ¤ ì—°ì‚°ì˜ ë‹¨ì 

âŒ ìë™ ë¯¸ë¶„(Autograd) ì‚¬ìš© ì‹œ ë¬¸ì œ ë°œìƒ ê°€ëŠ¥

x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)

y = x.add_(1)  # ì¸í”Œë ˆì´ìŠ¤ ì—°ì‚°
y.backward(torch.tensor([1.0, 1.0, 1.0]))  # ì˜¤ë¥˜ ë°œìƒ ê°€ëŠ¥

â¡ ì¸í”Œë ˆì´ìŠ¤ ì—°ì‚°ì€ PyTorchì˜ Autograd(ìë™ ë¯¸ë¶„) ê¸°ëŠ¥ê³¼ ì¶©ëŒí•  ê°€ëŠ¥ì„±ì´ ìˆìŒ
â¡ ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚° ì‹œ ì˜¤ë¥˜ê°€ ë°œìƒí•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ í•™ìŠµ ì¤‘ì—ëŠ” ì£¼ì˜ í•„ìš”!

5. ì¸í”Œë ˆì´ìŠ¤ ì—°ì‚° ì‚¬ìš© ì‹œ ì£¼ì˜í•  ì 
âœ… ë©”ëª¨ë¦¬ ì ˆì•½ì´ í•„ìš”í•  ë•Œ ì‚¬ìš©
âœ… í•™ìŠµ ì¤‘(Backpropagation)ì—ëŠ” ì‚¬ìš©ì„ í”¼í•˜ëŠ” ê²ƒì´ ì¢‹ìŒ
âœ… x.copy_(), x.zero_()ì™€ ê°™ì€ ì´ˆê¸°í™” ì—°ì‚°ì—ì„œë„ ì‚¬ìš©ë¨

6. ê²°ë¡ 
ì¸í”Œë ˆì´ìŠ¤ ì—°ì‚°(x.add_())ì€ ê¸°ì¡´ í…ì„œë¥¼ ë³€ê²½í•˜ëŠ” ì—°ì‚°
ë©”ëª¨ë¦¬ ì ˆì•½ì´ ê°€ëŠ¥í•˜ì§€ë§Œ, ìë™ ë¯¸ë¶„ê³¼ ì¶©ëŒí•  ìˆ˜ ìˆì–´ í•™ìŠµ ì¤‘ì—ëŠ” ì£¼ì˜ê°€ í•„ìš”
ëª¨ë¸ í•™ìŠµë³´ë‹¤ ì¶”ë¡ (Inference) ì‹œ ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ ì ì ˆíˆ ì‚¬ìš©í•˜ë©´ ìœ ìš©


=============================================================================
2-2-PyTorch view() í•¨ìˆ˜


torch.view() í•¨ìˆ˜ëŠ” PyTorchì—ì„œ
**í…ì„œì˜ í¬ê¸°ë¥¼ ë³€ê²½(Reshape)**í•  ë•Œ ì‚¬ìš©í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.

í•˜ì§€ë§Œ view()ëŠ” ê¸°ì¡´ ë©”ëª¨ë¦¬ë¥¼ ìœ ì§€í•˜ë©´ì„œ í¬ê¸°ë§Œ ë³€ê²½í•˜ëŠ” íŠ¹ì§•ì´ ìˆìŠµë‹ˆë‹¤.

(ì¦‰, ë°ì´í„° ìì²´ëŠ” ë³€í•˜ì§€ ì•Šê³ , í…ì„œì˜ ë©”ëª¨ë¦¬ ë ˆì´ì•„ì›ƒì„ ì¬êµ¬ì„±)

1. view()ì˜ ê¸°ë³¸ ë¬¸ë²•

tensor.view(shape)
shape: ë³€ê²½í•  í…ì„œì˜ í¬ê¸° ((rows, columns, ...))

-1ì„ ì‚¬ìš©í•˜ë©´ ìë™ìœ¼ë¡œ í¬ê¸°ë¥¼ ê³„ì‚°í•˜ì—¬ ì„¤ì •

2. view() ì˜ˆì œ: 1D â†’ 2D ë³€í™˜

import torch

x = torch.arange(6)  # 1D í…ì„œ (0~5)
print("Original Shape:", x.shape)

xreshaped = x.view(2, 3)  # 2í–‰ 3ì—´ë¡œ ë³€ê²½

print("Reshaped Shape:", xreshaped.shape)
print(xreshaped)

ğŸ“Œ ì‹¤í–‰ ê²°ê³¼


Original Shape: torch.Size([6])
Reshaped Shape: torch.Size([2, 3])
tensor([[0, 1, 2],
        [3, 4, 5]])

âœ… ë°ì´í„°ëŠ” ìœ ì§€ë˜ì§€ë§Œ, Shapeì´ ë³€ê²½ë¨!


3. view(-1): ìë™ í¬ê¸° ê³„ì‚°
-1ì„ ì‚¬ìš©í•˜ë©´ PyTorchê°€ ìë™ìœ¼ë¡œ í¬ê¸°ë¥¼ ê³„ì‚°í•˜ì—¬ ì„¤ì •í•©ë‹ˆë‹¤.

x = torch.arange(12)
xreshaped = x.view(3, -1)  # ì—´(-1)ì€ ìë™ ê³„ì‚°ë¨

print(xreshaped.shape)
print(xreshaped)

ğŸ“Œ ì‹¤í–‰ ê²°ê³¼

torch.Size([3, 4])
tensor([[ 0,  1,  2,  3],
        [ 4,  5,  6,  7],
        [ 8,  9, 10, 11]])

âœ… -1ì€ ìë™ìœ¼ë¡œ 4ë¡œ ê³„ì‚°ë¨ (3 Ã— 4 = 12 ìš”ì†Œ ê°œìˆ˜ ìœ ì§€)

4. 3D â†’ 2D ë³€í™˜ ì˜ˆì œ


x = torch.arange(24).view(2, 3, 4)  # 3D í…ì„œ ìƒì„± (ë°°ì¹˜=2, í–‰=3, ì—´=4)

print("3D Tensor Shape:", x.shape)

xflattened = x.view(2, -1)  # ë°°ì¹˜ ìœ ì§€, ë‚˜ë¨¸ì§€ëŠ” ìë™ ì¡°ì •
print("Flattened Shape:", xflattened.shape)

ğŸ“Œ ì‹¤í–‰ ê²°ê³¼

3D Tensor Shape: torch.Size([2, 3, 4])
Flattened Shape: torch.Size([2, 12])

âœ… 3D í…ì„œë¥¼ 2Dë¡œ ë³€í™˜ (ë°°ì¹˜=2 ìœ ì§€, 3Ã—4=12 ê°œìˆ˜ ìë™ ê³„ì‚°)

5. view() ì‚¬ìš© ì‹œ ì£¼ì˜í•  ì 

1ì—°ì†ëœ ë©”ëª¨ë¦¬(Contiguous) í•„ìš”

view()ëŠ” ë©”ëª¨ë¦¬ ì—°ì†ì„±ì´ ìœ ì§€ë˜ëŠ” ê²½ìš°ì—ë§Œ ì‚¬ìš© ê°€ëŠ¥
ë§Œì•½ ì—°ì†ì ì´ì§€ ì•Šë‹¤ë©´ .contiguous().view()ë¥¼ ì‚¬ìš©í•´ì•¼ í•¨


x = torch.randn(2, 3, 4)  # (Batch=2, Rows=3, Cols=4)
xt = x.transpose(0, 1)    # (Rows=3, Batch=2, Cols=4) â†’ ë©”ëª¨ë¦¬ ë¹„ì—°ì†

 ì°¨ì› ë³€ê²½ì´ ë©”ëª¨ë¦¬ ë¹„ì—°ì†ì„±ì„ ì´ˆë˜í•˜ëŠ” ì´ìœ 
PyTorchì—ì„œ í…ì„œëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ì—°ì†ì ì¸ ë©”ëª¨ë¦¬(Contiguous Memory) ì— ì €ì¥ë¨.
transpose(dim0, dim1)ì„ ì‚¬ìš©í•˜ë©´ ì‹¤ì œ ë°ì´í„° ë°°ì—´ì„ ë³€ê²½í•˜ì§€ ì•Šê³ ,
ì¸ë±ìŠ¤ë§Œ ë³€ê²½í•˜ì—¬ ìƒˆë¡œìš´ ë·°ë¥¼ ìƒì„±.
ë”°ë¼ì„œ ë©”ëª¨ë¦¬ ìƒì—ì„œ ë°ì´í„°ê°€ ì—°ì†ë˜ì§€ ì•ŠìŒ(Non-contiguous).

xview = xt.contiguous().view(2, -1)  # ì—°ì†ëœ ë©”ëª¨ë¦¬ë¡œ ë³€ê²½ í›„ View ì ìš©

2ì›ì†Œ ê°œìˆ˜(Elements) ìœ ì§€ í•„ìš”

view()ë¥¼ ì‚¬ìš©í•˜ë©´ ê¸°ì¡´ í…ì„œì˜ ì›ì†Œ ê°œìˆ˜ê°€ ê·¸ëŒ€ë¡œ ìœ ì§€ë˜ì–´ì•¼ í•¨
ê°œìˆ˜ê°€ ë§ì§€ ì•Šìœ¼ë©´ ì˜¤ë¥˜ ë°œìƒ


x = torch.arange(10)
x.view(3, 3)  # 10ê°œ ì›ì†Œë¥¼ (3Ã—3)ë¡œ ë³€ê²½í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ ì˜¤ë¥˜ ë°œìƒ!

RuntimeError: shape '[3, 3]' is invalid for input of size 10

6. view()ì™€ reshape() ì°¨ì´

í•¨ìˆ˜	íŠ¹ì§•
view()	ë©”ëª¨ë¦¬ ì—°ì†ì„± ìœ ì§€ í•„ìš”, ì†ë„ ë¹ ë¦„
reshape()	ë©”ëª¨ë¦¬ ì—°ì†ì„± ì—†ì–´ë„ ì‚¬ìš© ê°€ëŠ¥

âœ… ì°¨ì´ì  ì˜ˆì œ

x = torch.randn(2, 3)
xt = x.transpose(0, 1)  # ì°¨ì› ë³€ê²½ â†’ ë©”ëª¨ë¦¬ ë¹„ì—°ì†

# view() ì˜¤ë¥˜ ë°œìƒ
try:
    xview = xt.view(6)
except RuntimeError as e:
    print("view() Error:", e)

# reshape()ëŠ” ìë™ìœ¼ë¡œ í•´ê²°
xreshape = xt.reshape(6)
print("reshape() ì„±ê³µ:", xreshape.shape)

âœ… ë©”ëª¨ë¦¬ ì—°ì†ì„±ì´ ì—†ëŠ” ê²½ìš° view()ëŠ” ì‹¤íŒ¨í•˜ì§€ë§Œ reshape()ëŠ” ê°€ëŠ¥!

âœ… ê²°ë¡ 
view()ëŠ” ê¸°ì¡´ ë©”ëª¨ë¦¬ë¥¼ ìœ ì§€í•˜ë©´ì„œ í…ì„œì˜ shapeì„ ë³€ê²½í•˜ëŠ” í•¨ìˆ˜
ë©”ëª¨ë¦¬ ì—°ì†ì„±ì´ í•„ìš”í•˜ë©°, contiguous()ë¥¼ ì‚¬ìš©í•´ì•¼ í•  ìˆ˜ë„ ìˆìŒ
ì›ì†Œ ê°œìˆ˜ëŠ” ìœ ì§€ë˜ì–´ì•¼ í•˜ë©°, -1ì„ ì‚¬ìš©í•˜ë©´ ìë™ ê³„ì‚° ê°€ëŠ¥

ë¹„ì—°ì† ë©”ëª¨ë¦¬ í…ì„œëŠ” reshape()ê°€ ë” ì•ˆì „í•¨

=============================================================================
2-3-squeeze() vs unsqueeze() í•¨ìˆ˜ ì°¨ì´ì 

1ï¸âƒ£ squeeze() í•¨ìˆ˜
âœ… í¬ê¸°ê°€ 1ì¸ ì°¨ì›(dim)ì„ ì œê±°í•©ë‹ˆë‹¤.

python
ì½”ë“œ ë³µì‚¬
import torch

# (1, 3, 1, 4) í¬ê¸°ì˜ í…ì„œ ìƒì„±
x = torch.rand(1, 3, 1, 4)
print("Original shape:", x.shape)  # torch.Size([1, 3, 1, 4])

# squeeze() ì‚¬ìš©
x_squeezed = x.squeeze()
print("Squeezed shape:", x_squeezed.shape)  # torch.Size([3, 4])

ğŸ”¹ì„¤ëª…
squeeze()ëŠ” í¬ê¸°ê°€ 1ì¸ ì°¨ì›ë§Œ ìë™ìœ¼ë¡œ ì œê±°í•©ë‹ˆë‹¤.
(1, 3, 1, 4) â†’ (3, 4)ë¡œ ë³€í™˜ë¨.
ì£¼ì˜! squeeze(dim=n)ì„ ì‚¬ìš©í•˜ë©´ íŠ¹ì • ì°¨ì›ë§Œ ì œê±°í•  ìˆ˜ ìˆìŒ.

x_squeezed_dim1 = x.squeeze(0)  # dim=0ì´ 1ì´ë¯€ë¡œ ì œê±°ë¨
print(x_squeezed_dim1.shape)  # torch.Size([3, 1, 4])

x_squeezed_dim2 = x.squeeze(2)  # dim=2ê°€ 1ì´ë¯€ë¡œ ì œê±°ë¨
print(x_squeezed_dim2.shape)  # torch.Size([1, 3, 4])

2ï¸âƒ£ unsqueeze() í•¨ìˆ˜
âœ… íŠ¹ì • ì°¨ì›(dim)ì— í¬ê¸°ê°€ 1ì¸ ì°¨ì›ì„ ì¶”ê°€í•©ë‹ˆë‹¤.

python
ì½”ë“œ ë³µì‚¬
y = torch.rand(3, 4)  # (3, 4) í¬ê¸°ì˜ í…ì„œ
print("Original shape:", y.shape)  # torch.Size([3, 4])

# unsqueeze() ì‚¬ìš© (dim=0ì— ìƒˆë¡œìš´ ì°¨ì› ì¶”ê°€)
y_unsqueezed = y.unsqueeze(0)
print("Unsqueezed shape:", y_unsqueezed.shape)  # torch.Size([1, 3, 4])

ğŸ”¹ì„¤ëª…
unsqueeze(dim=n)ì€ íŠ¹ì • ì°¨ì›ì— í¬ê¸° 1ì¸ ì°¨ì›ì„ ì¶”ê°€í•©ë‹ˆë‹¤.
(3, 4) â†’ (1, 3, 4)ë¡œ ë³€í™˜ë¨.


PyTorchì—ì„œ squeeze()ì™€ unsqueeze()ëŠ” í…ì„œì˜ ì°¨ì›ì„ ë³€ê²½í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.

ğŸ”¹ 1ï¸ squeeze(): í¬ê¸°ê°€ 1ì¸ ì°¨ì› ì œê±°

ğŸ“Œ ì„¤ëª…
squeeze()ëŠ” í¬ê¸°ê°€ 1ì¸ ì°¨ì›ì„ ìë™ìœ¼ë¡œ ì œê±°í•©ë‹ˆë‹¤.
ë°ì´í„°ì˜ êµ¬ì¡°ë¥¼ ì¶•ì†Œí•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.

ğŸ“Œ ì˜ˆì œ

import torch

x = torch.randn(1, 3, 1, 4)  # (Batch=1, Channels=3, Height=1, Width=4)

x_squeezed = x.squeeze()  # í¬ê¸°ê°€ 1ì¸ ì°¨ì›ì„ ì œê±°

print(x.shape)          # torch.Size([1, 3, 1, 4])
print(x_squeezed.shape) # torch.Size([3, 4])
(1, 3, 1, 4) â†’ (3, 4) ë¡œ ë³€ê²½ë¨ (í¬ê¸°ê°€ 1ì¸ ì°¨ì› ì œê±°)

ğŸ“Œ íŠ¹ì • ì°¨ì›ë§Œ ì œê±°í•˜ê¸°

x_squeezed_1 = x.squeeze(0)  # 0ë²ˆ ì°¨ì›(í¬ê¸°ê°€ 1ì¸ ê²½ìš°ë§Œ) ì œê±°
x_squeezed_2 = x.squeeze(2)  # 2ë²ˆ ì°¨ì›(í¬ê¸°ê°€ 1ì¸ ê²½ìš°ë§Œ) ì œê±°

print(x_squeezed_1.shape)  # torch.Size([3, 1, 4])
print(x_squeezed_2.shape)  # torch.Size([1, 3, 4])
squeeze(dim)ì„ ì‚¬ìš©í•˜ë©´ íŠ¹ì • ì°¨ì›ë§Œ ì œê±° ê°€ëŠ¥.

ğŸ”¹ 2ï¸ unsqueeze(): í¬ê¸°ê°€ 1ì¸ ì°¨ì› ì¶”ê°€

ğŸ“Œ ì„¤ëª…
unsqueeze(dim)ì€ ì§€ì •í•œ dim ìœ„ì¹˜ì— í¬ê¸°ê°€ 1ì¸ ì°¨ì›ì„ ì¶”ê°€í•©ë‹ˆë‹¤.

ë°°ì¹˜ ì°¨ì› ì¶”ê°€, ì±„ë„ ì°¨ì› ì¶”ê°€ ë“±ì— ì‚¬ìš©ë¨.

ğŸ“Œ ì˜ˆì œ

y = torch.randn(3, 4)  # (3, 4) í˜•íƒœ
y_unsqueezed = y.unsqueeze(0)  # 0ë²ˆ ì°¨ì› ì¶”ê°€

print(y.shape)           # torch.Size([3, 4])
print(y_unsqueezed.shape) # torch.Size([1, 3, 4])

(3, 4) â†’ (1, 3, 4) ë¡œ ë³€ê²½ë¨

ğŸ“Œ ì—¬ëŸ¬ ì°¨ì› ì¶”ê°€

y_unsqueezed_1 = y.unsqueeze(1)  # 1ë²ˆ ì°¨ì›ì— ì¶”ê°€
y_unsqueezed_2 = y.unsqueeze(2)  # 2ë²ˆ ì°¨ì›ì— ì¶”ê°€

print(y_unsqueezed_1.shape)  # torch.Size([3, 1, 4])
print(y_unsqueezed_2.shape)  # torch.Size([3, 4, 1])

unsqueeze(1): ì±„ë„ ì°¨ì› ì¶”ê°€í•  ë•Œ ìœ ìš©
unsqueeze(0): ë°°ì¹˜ ì°¨ì› ì¶”ê°€í•  ë•Œ ìœ ìš©

âœ… squeeze() vs unsqueeze() ì°¨ì´ ì •ë¦¬

í•¨ìˆ˜	ê¸°ëŠ¥	ê²°ê³¼ ì˜ˆì‹œ
squeeze()	í¬ê¸° 1ì¸ ì°¨ì›ì„ ì œê±°	(1, 3, 1, 4) â†’ (3, 4)
unsqueeze(dim)	íŠ¹ì • ìœ„ì¹˜ì— í¬ê¸° 1ì¸ ì°¨ì› ì¶”ê°€	(3, 4) â†’ (1, 3, 4)

ğŸ“Œ unsqueeze()ë¥¼ í™œìš©í•œ ë°°ì¹˜ ì¶”ê°€


x = torch.randn(3, 4)   # (3, 4)
x_batch = x.unsqueeze(0) # ë°°ì¹˜ ì°¨ì› ì¶”ê°€ â†’ (1, 3, 4)

ğŸ“Œ squeeze()ë¥¼ í™œìš©í•œ ì°¨ì› ì¶•ì†Œ

x = torch.randn(1, 3, 1, 4)
x_squeezed = x.squeeze()  # í¬ê¸°ê°€ 1ì¸ ì°¨ì› ì œê±° â†’ (3, 4)

=============================================================================
2-3-2-torch.cat([x.unsqueeze(0), y.unsqueeze(0)], dim=0) ì˜ˆì œ



ğŸ“Œ ì˜ˆì œ ì½”ë“œ: unsqueeze(0)ì™€ cat() ì‚¬ìš©


import torch

# 2D í…ì„œ ìƒì„± (2x3 í¬ê¸°)
x = torch.tensor([[1, 2, 3], [4, 5, 6]])  # Shape: (2,3)
y = torch.tensor([[7, 8, 9], [10, 11, 12]])  # Shape: (2,3)

# unsqueeze(0)ì„ í†µí•´ ìƒˆë¡œìš´ ì°¨ì› ì¶”ê°€ í›„ cat() ì ìš©
z = torch.cat([x.unsqueeze(0), y.unsqueeze(0)], dim=0)

# ê²°ê³¼ ì¶œë ¥
print("Original x shape:", x.shape)
print("Original y shape:", y.shape)
print("After unsqueeze and cat, z shape:", z.shape)
print("z Tensor:\n", z)

ğŸ“Œ ì˜ˆìƒ ì¶œë ¥ ê²°ê³¼

plaintext

Original x shape: torch.Size([2, 3])
Original y shape: torch.Size([2, 3])
After unsqueeze and cat, z shape: torch.Size([2, 2, 3])
z Tensor:
 tensor([[[ 1,  2,  3],
          [ 4,  5,  6]],

         [[ 7,  8,  9],
          [10, 11, 12]]])
ğŸ”¹ ì„¤ëª…
unsqueeze(0):

x.unsqueeze(0) â†’ (2,3) â†’ (1,2,3)
y.unsqueeze(0) â†’ (2,3) â†’ (1,2,3)

cat(dim=0):

(1,2,3) + (1,2,3) â†’ (2,2,3)

ì¦‰, ë‘ ê°œì˜ (2,3) í…ì„œë¥¼ ìƒˆë¡œìš´ ì°¨ì›(0ë²ˆ ì°¨ì›)ìœ¼ë¡œ ì—°ê²°í•˜ì—¬ (2,2,3)ì´ ë¨.

âœ… ì •ë¦¬
ì—°ì‚°	ì°¨ì› ë³€í™”
x.shape	(2,3)
x.unsqueeze(0).shape	(1,2,3)
y.unsqueeze(0).shape	(1,2,3)
torch.cat([x.unsqueeze(0), y.unsqueeze(0)], dim=0)	(2,2,3)

âœ… ì´ ë°©ë²•ì€ ë°°ì¹˜(batch) ì°¨ì›ì„ ì¶”ê°€í•  ë•Œ ìœ ìš©í•˜ë©°,
CNN ì…ë ¥ ë°ì´í„°ì²˜ëŸ¼ ì‚¬ìš©ë  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.

=============================================================================
2-4-2-í…ì„œ(Tensor) í¬ê¸° ë° ìš”ì†Œ ë³€í™” ê°œë… ì„¤ëª…



**í…ì„œ(Tensor)**ëŠ” ë‹¤ì°¨ì› ë°°ì—´ì„ ì˜ë¯¸í•˜ë©°,
**ë²¡í„°(Vector), í–‰ë ¬(Matrix), ë‹¤ì°¨ì› ë°°ì—´(ND-array)**ì„ ì¼ë°˜í™”í•œ ê°œë…ì…ë‹ˆë‹¤.

PyTorchì—ì„œëŠ” torch.Tensorë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¤ì°¨ì› ë°ì´í„°ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.

1. í…ì„œì˜ ê¸°ë³¸ ê°œë…

ì°¨ì›	ì˜ë¯¸	ì˜ˆì œ

0D (ìŠ¤ì¹¼ë¼, Scalar)	í•˜ë‚˜ì˜ ìˆ«ì	torch.tensor(5)
1D (ë²¡í„°, Vector)	ìˆ«ìì˜ ë¦¬ìŠ¤íŠ¸	torch.tensor([1, 2, 3])
2D (í–‰ë ¬, Matrix)	í–‰ê³¼ ì—´ì´ ìˆëŠ” ë°°ì—´	torch.tensor([[1, 2], [3, 4]])
3D ì´ìƒ (ë‹¤ì°¨ì› í…ì„œ, ND-Tensor)	ì—¬ëŸ¬ ê°œì˜ í–‰ë ¬ë¡œ êµ¬ì„±ëœ êµ¬ì¡°
torch.tensor([[[1,2], [3,4]], [[5,6], [7,8]]])

2. í…ì„œ í¬ê¸°(Shape) ì´í•´
PyTorchì—ì„œ tensor.shapeì„ í™•ì¸í•˜ë©´ í…ì„œì˜ ì°¨ì›ê³¼ í¬ê¸°ë¥¼ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

import torch

# 0D í…ì„œ (ìŠ¤ì¹¼ë¼)
scalar = torch.tensor(42)
print("Scalar Shape:", scalar.shape)  # ()

# 1D í…ì„œ (ë²¡í„°)
vector = torch.tensor([1, 2, 3])
print("Vector Shape:", vector.shape)  # (3,)

# 2D í…ì„œ (í–‰ë ¬)
matrix = torch.tensor([[1, 2, 3], [4, 5, 6]])
print("Matrix Shape:", matrix.shape)  # (2, 3)

# 3D í…ì„œ (ë‹¤ì°¨ì› ë°°ì—´)
tensor_3d = torch.tensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])
print("3D Tensor Shape:", tensor_3d.shape)  # (2, 2, 2)

ğŸ“Œ ì‹¤í–‰ ê²°ê³¼

Scalar Shape: torch.Size([])
Vector Shape: torch.Size([3])
Matrix Shape: torch.Size([2, 3])
3D Tensor Shape: torch.Size([2, 2, 2])

âœ… ê° í…ì„œì˜ shapeì„ ë³´ë©´ ì°¨ì›ì´ ì–´ë–»ê²Œ êµ¬ì„±ë˜ëŠ”ì§€ í™•ì¸ ê°€ëŠ¥!

3. í…ì„œ ìš”ì†Œ ë³€í™” ì˜ˆì‹œ

âœ… 1) reshape()ì„ í™œìš©í•œ í˜•íƒœ ë³€ê²½

x = torch.arange(6)  # [0, 1, 2, 3, 4, 5]
print("Original Shape:", x.shape)  # (6,)

x_reshaped = x.reshape(2, 3)  # 2í–‰ 3ì—´ë¡œ ë³€ê²½
print("Reshaped Shape:", x_reshaped.shape)  # (2, 3)
print(x_reshaped)

ğŸ“Œ ì‹¤í–‰ ê²°ê³¼

Original Shape: torch.Size([6])
Reshaped Shape: torch.Size([2, 3])
tensor([[0, 1, 2],
        [3, 4, 5]])

âœ… reshapeì„ ì‚¬ìš©í•˜ë©´ í…ì„œì˜ shapeì„ ë³€ê²½ ê°€ëŠ¥
âœ… ë°ì´í„°ì˜ ê°œìˆ˜(ìš”ì†Œ ê°œìˆ˜)ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€ë˜ì§€ë§Œ, ì°¨ì›ë§Œ ë³€ê²½ë¨


âœ… 2) unsqueeze()ë¥¼ í™œìš©í•œ ì°¨ì› ì¶”ê°€


x = torch.tensor([1, 2, 3])
print("Original Shape:", x.shape)  # (3,)

x_unsqueezed = x.unsqueeze(0)  # ì°¨ì› ì¶”ê°€ (ë°°ì¹˜ ì°¨ì› ì¶”ê°€)
print("Unsqueezed Shape:", x_unsqueezed.shape)  # (1, 3)

ğŸ“Œ ì‹¤í–‰ ê²°ê³¼

Original Shape: torch.Size([3])
Unsqueezed Shape: torch.Size([1, 3])

âœ… unsqueeze(dim=0)ì„ ì‚¬ìš©í•˜ë©´ (3,) â†’ (1, 3)ë¡œ ì°¨ì›ì´ ì¶”ê°€ë¨
âœ… CNN ëª¨ë¸ì—ì„œ ë°°ì¹˜ ì°¨ì›ì„ ì¶”ê°€í•  ë•Œ ìì£¼ ì‚¬ìš©ë¨

âœ… 3) squeeze()ë¥¼ í™œìš©í•œ ì°¨ì› ì¶•ì†Œ


x = torch.tensor([[1, 2, 3]])  # (1, 3)
print("Original Shape:", x.shape)

x_squeezed = x.squeeze()
print("Squeezed Shape:", x_squeezed.shape)  # (3,)

ğŸ“Œ ì‹¤í–‰ ê²°ê³¼

Original Shape: torch.Size([1, 3])
Squeezed Shape: torch.Size([3])
âœ… squeeze()ë¥¼ ì‚¬ìš©í•˜ë©´ ë¶ˆí•„ìš”í•œ ì°¨ì›ì´ ì œê±°ë¨
âœ… (1, 3) â†’ (3)ë¡œ ë³€ê²½ë¨

âœ… 4) permute()ë¥¼ í™œìš©í•œ ì°¨ì› ìˆœì„œ ë³€ê²½

x = torch.randn(3, 4, 5)  # (ì±„ë„, ë†’ì´, ë„ˆë¹„)
print("Original Shape:", x.shape)  # (3, 4, 5)

x_permuted = x.permute(1, 2, 0)  # (ë†’ì´, ë„ˆë¹„, ì±„ë„)ë¡œ ë³€ê²½

print("Permuted Shape:", x_permuted.shape)  # (4, 5, 3)

ğŸ“Œ ì‹¤í–‰ ê²°ê³¼

Original Shape: torch.Size([3, 4, 5])
Permuted Shape: torch.Size([4, 5, 3])
âœ… CNNì—ì„œ ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ë³€í™˜í•  ë•Œ ìì£¼ ì‚¬ìš©ë¨
âœ… ì±„ë„-ë†’ì´-ë„ˆë¹„ êµ¬ì¡°ë¥¼ ë†’ì´-ë„ˆë¹„-ì±„ë„ êµ¬ì¡°ë¡œ ë³€ê²½ ê°€ëŠ¥

4. í…ì„œ ì—°ì‚°ì„ í†µí•œ ìš”ì†Œ ë³€í™”

x = torch.tensor([[1, 2], [3, 4]])
print("Original Tensor:")
print(x)

# í…ì„œ ê°’ ë³€ê²½ (ì—°ì‚° ìˆ˜í–‰)
y = x * 2  # ìš”ì†Œë³„ ì—°ì‚° (ëª¨ë“  ì›ì†Œë¥¼ 2ë°°)
print("After Multiplication by 2:")
print(y)

# ìš”ì†Œë³„ ì œê³± ì—°ì‚°
z = x ** 2
print("After Squaring:")
print(z)

ğŸ“Œ ì‹¤í–‰ ê²°ê³¼


Original Tensor:
tensor([[1, 2],
        [3, 4]])

After Multiplication by 2:
tensor([[2, 4],
        [6, 8]])

After Squaring:
tensor([[ 1,  4],
        [ 9, 16]])

âœ… í…ì„œì˜ ìš”ì†Œ ê°’ì„ ì—°ì‚°ì„ í†µí•´ ë³€ê²½ ê°€ëŠ¥
âœ… ë¸Œë¡œë“œìºìŠ¤íŒ…ì„ í†µí•´ ëª¨ë“  ì›ì†Œì— ë™ì¼í•œ ì—°ì‚° ì ìš© ê°€ëŠ¥

5. ê²°ë¡ 
ğŸ“Œ í…ì„œ í¬ê¸° ê°œë… ì •ë¦¬
0D í…ì„œ (ìŠ¤ì¹¼ë¼): ìˆ«ì í•˜ë‚˜
1D í…ì„œ (ë²¡í„°): ë¦¬ìŠ¤íŠ¸ í˜•íƒœì˜ ë°°ì—´
2D í…ì„œ (í–‰ë ¬): í–‰ê³¼ ì—´ì´ ìˆëŠ” ë°°ì—´
3D ì´ìƒ í…ì„œ: ë‹¤ì°¨ì› ë°°ì—´

ğŸ“Œ ì£¼ìš” í…ì„œ ë³€í™˜ ì—°ì‚°
ì—°ì‚°	ì„¤ëª…	ì˜ˆì œ
reshape()	í¬ê¸° ë³€ê²½ (ìš”ì†Œ ê°œìˆ˜ ìœ ì§€)	(6,) â†’ (2, 3)
unsqueeze()	ì°¨ì› ì¶”ê°€	(3,) â†’ (1, 3)
squeeze()	ì°¨ì› ì œê±°	(1, 3, 1) â†’ (3,)
permute()	ì°¨ì› ìˆœì„œ ë³€ê²½	(3, 4, 5) â†’ (4, 5, 3)

ğŸ“Œ í…ì„œ ì—°ì‚°
ë§ì…ˆ, ëº„ì…ˆ, ê³±ì…ˆ ë“± ìš”ì†Œë³„ ì—°ì‚° ê°€ëŠ¥
ë¸Œë¡œë“œìºìŠ¤íŒ…ì„ í†µí•´ ìë™ìœ¼ë¡œ í¬ê¸° ë§ì¶¤
CNN, RNNì—ì„œ ë°ì´í„° ë³€í™˜ ì‹œ í•„ìˆ˜ì 


=============================================================================
2-4-3-ì…ë ¥ ë°ì´í„° shape ë° ì¶œë ¥ ë°ì´í„° shape ë¶„ì„

ìœ„ ì½”ë“œì—ì„œ ì…ë ¥ ë°ì´í„° Xì™€ ì¶œë ¥ ë°ì´í„° Yì˜ shape(ëª¨ì–‘)ì„ ë¶„ì„í•˜ê³ ,

ëª¨ë¸ì˜ ê° ë ˆì´ì–´ë¥¼ í†µê³¼í•  ë•Œ ë°ì´í„°ê°€ ì–´ë–»ê²Œ ë³€í•˜ëŠ”ì§€ ì„¤ëª…í•˜ê² ìŠµë‹ˆë‹¤.

1. ì…ë ¥ ë°ì´í„° Xì™€ ì •ë‹µ ë°ì´í„° Yì˜ shape



X = torch.tensor([[0, 0],
                  [0, 1],
                  [1, 0],
                  [1, 1]], dtype=torch.float32)  # ì…ë ¥ê°’
Y = torch.tensor(
[[0],
[1],
[1],
[0]], dtype=torch.float32)  # ì •ë‹µê°’

ë°ì´í„°	ë‚´ìš©	Shape
X	4ê°œì˜ ìƒ˜í”Œ, ê° ìƒ˜í”Œì€ 2ê°œì˜ ì…ë ¥ íŠ¹ì„±(0 ë˜ëŠ” 1)	(4, 2)
Y	4ê°œì˜ ìƒ˜í”Œ, ê° ìƒ˜í”Œì˜ ì •ë‹µ(0 ë˜ëŠ” 1)	(4, 1)

ğŸ“Œ ì¦‰, XëŠ” (batch_size, input_dim) = (4, 2) í˜•íƒœì˜ ì…ë ¥ì„ ê°€ì§

ğŸ“Œ ì •ë‹µ YëŠ” (batch_size, output_dim) = (4, 1) í˜•íƒœì˜ ì¶œë ¥ì„ ê¸°ëŒ€í•¨


2. forward() í•¨ìˆ˜ì—ì„œ ë°ì´í„° íë¦„ê³¼ shape ë³€í™”

def forward(self, x):
    x = self.activation(self.hidden(x))  # ì€ë‹‰ì¸µ í™œì„±í™”
    x = self.activation(self.output(x))  # ì¶œë ¥ì¸µ í™œì„±í™”
    return x

(1) ì…ë ¥ì¸µ â†’ ì€ë‹‰ì¸µ ë³€í™˜ (self.hidden(x))


self.hidden = nn.Linear(2, 2)  # (input_dim=2 â†’ hidden_dim=2)

X.shape = (4, 2) â†’ hidden(x)ì„ í†µê³¼í•˜ë©´ (4, 2)
ì„ í˜• ë³€í™˜ ê³µì‹:

Z1 = X * W1 + b1



(2) ì€ë‹‰ì¸µ í™œì„±í™” (self.activation(hidden(x)))
í™œì„±í™” í•¨ìˆ˜ Sigmoid ì ìš© â†’ shape ë³€í™” ì—†ìŒ
x.shape = (4, 2)

(3) ì€ë‹‰ì¸µ â†’ ì¶œë ¥ì¸µ ë³€í™˜ (self.output(x))

 self.output = nn.Linear(2, 1)  # (hidden_dim=2 â†’ output_dim=1)
x.shape = (4, 2) â†’ output(x)ì„ í†µê³¼í•˜ë©´ (4, 1)

ì„ í˜• ë³€í™˜ ê³µì‹:
Z2 = A1 * W2 + b2

(4,2) Ã— (2,1) = (4,1)

â€‹
 ì˜ shape: (4, 1)

(4) ì¶œë ¥ì¸µ í™œì„±í™” (self.activation(output(x)))
í™œì„±í™” í•¨ìˆ˜ Sigmoid ì ìš© â†’ shape ë³€í™” ì—†ìŒ
ìµœì¢… ì¶œë ¥ x.shape = (4, 1)

3. ë°ì´í„° íë¦„ Shape ë³€í™” ìš”ì•½
ë ˆì´ì–´	ì—°ì‚°	Shape ë³€í™”

ì…ë ¥ ë°ì´í„°	X	(4, 2)
ì€ë‹‰ì¸µ ì„ í˜• ë³€í™˜	self.hidden(x)	(4, 2)
ì€ë‹‰ì¸µ í™œì„±í™” í•¨ìˆ˜	self.activation(hidden(x))	(4, 2)
ì¶œë ¥ì¸µ ì„ í˜• ë³€í™˜	self.output(x)	(4, 1)
ì¶œë ¥ì¸µ í™œì„±í™” í•¨ìˆ˜	self.activation(output(x))	(4, 1)
ìµœì¢… ì¶œë ¥	Y_hat	(4, 1)

4. ì‹¤ì œ shape í™•ì¸ ì½”ë“œ
ëª¨ë¸ì„ ì‹¤í–‰í•˜ë©´ì„œ ê° ë ˆì´ì–´ì—ì„œ ë°ì´í„° shape ë³€í™”ë¥¼ ì§ì ‘ í™•ì¸í•´ ë³´ê² ìŠµë‹ˆë‹¤.


import torch
import torch.nn as nn

class XOR_NN(nn.Module):
    def __init__(self):
        super(XOR_NN, self).__init__()
        self.hidden = nn.Linear(2, 2)  # ì…ë ¥ 2 â†’ ì€ë‹‰ì¸µ 2
        self.output = nn.Linear(2, 1)  # ì€ë‹‰ì¸µ 2 â†’ ì¶œë ¥ì¸µ 1
        self.activation = nn.Sigmoid()  # í™œì„±í™” í•¨ìˆ˜

    def forward(self, x):
        print("ì…ë ¥ ë°ì´í„° shape:", x.shape)  # (4, 2)
        x = self.hidden(x)
        print("ì€ë‹‰ì¸µ í†µê³¼ í›„ shape:", x.shape)  # (4, 2)
        x = self.activation(x)
        print("ì€ë‹‰ì¸µ í™œì„±í™” í›„ shape:", x.shape)  # (4, 2)
        x = self.output(x)
        print("ì¶œë ¥ì¸µ í†µê³¼ í›„ shape:", x.shape)  # (4, 1)
        x = self.activation(x)
        print("ì¶œë ¥ì¸µ í™œì„±í™” í›„ shape:", x.shape)  # (4, 1)
        return x

# ëª¨ë¸ ìƒì„±
model = XOR_NN()

# ì…ë ¥ ë°ì´í„°
X = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)

# ëª¨ë¸ ì‹¤í–‰
output = model(X)

ğŸ“Œ ì‹¤í–‰ ê²°ê³¼


ì…ë ¥ ë°ì´í„° shape: torch.Size([4, 2])
ì€ë‹‰ì¸µ í†µê³¼ í›„ shape: torch.Size([4, 2])
ì€ë‹‰ì¸µ í™œì„±í™” í›„ shape: torch.Size([4, 2])
ì¶œë ¥ì¸µ í†µê³¼ í›„ shape: torch.Size([4, 1])
ì¶œë ¥ì¸µ í™œì„±í™” í›„ shape: torch.Size([4, 1])

5. ê²°ë¡ 
âœ… ì…ë ¥ ë°ì´í„° XëŠ” (4, 2)ë¡œ ì‹œì‘í•˜ë©°, ìµœì¢… ì¶œë ¥ Y_hatì€ (4, 1)ë¡œ ë³€í™˜ë¨
âœ… ì€ë‹‰ì¸µì—ì„œ ë‰´ëŸ° ê°œìˆ˜(2)ë¥¼ ìœ ì§€í•˜ë©°, ì¶œë ¥ì¸µì—ì„œ 1ê°œì˜ ê°’ìœ¼ë¡œ ì¤„ì–´ë“¦
âœ… ê° ë ˆì´ì–´ë¥¼ í†µê³¼í•  ë•Œ shape ë³€í™”ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì§„í–‰ë¨

(4, 2) â†’ (4, 2) â†’ (4, 2) â†’ (4, 1) â†’ (4, 1)

âœ… ëª¨ë¸ ì‹¤í–‰ ì‹œ print()ë¡œ shape ë³€í™”ë¥¼ ì§ì ‘ í™•ì¸ ê°€ëŠ¥

=============================================================================
2-4-4-3ì°¨ì› í…ì„œ(3D Tensor)ì—ì„œ ì¸ë±ìŠ¤ ë³„ ìœ„ì¹˜ ì´í•´

3ì°¨ì› í…ì„œ(3D Tensor)ì—ì„œ ì¸ë±ìŠ¤ ë³„ ìœ„ì¹˜ ì´í•´

âœ… 3ì°¨ì› í…ì„œì˜ ê¸°ë³¸ ê°œë…
3ì°¨ì› í…ì„œëŠ” ë‹¤ìŒê³¼ ê°™ì€ **3ê°œì˜ ì°¨ì›(Dimension)**ì„ ê°€ì§‘ë‹ˆë‹¤.

3D Tensor Shape: (D1, D2, D3)

ì²« ë²ˆì§¸ ì°¨ì› (D_1) â†’ ì¼ë°˜ì ìœ¼ë¡œ ë°°ì¹˜ í¬ê¸°(Batch Size), ì±„ë„ ìˆ˜(Channel)
ë‘ ë²ˆì§¸ ì°¨ì› (D_2) â†’ í–‰(Row) ë˜ëŠ” ë†’ì´(Height)
ì„¸ ë²ˆì§¸ ì°¨ì› (D_3) â†’ ì—´(Column) ë˜ëŠ” ë„ˆë¹„(Width)

ì¦‰, (ë°°ì¹˜, ë†’ì´, ë„ˆë¹„) = (D_1, D_2, D_3) í˜•íƒœë¡œ ì´í•´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

1. 3D í…ì„œ ìƒì„± ë° ê° ì¸ë±ìŠ¤ ë³„ ìœ„ì¹˜ í™•ì¸

import torch

# 3D í…ì„œ ìƒì„± (ë°°ì¹˜=2, ë†’ì´=3, ë„ˆë¹„=4)
tensor_3d = torch.tensor([
    [[1, 2, 3, 4],
     [5, 6, 7, 8],
     [9, 10, 11, 12]],  # ì²« ë²ˆì§¸ ë°°ì¹˜

    [[13, 14, 15, 16],
     [17, 18, 19, 20],
     [21, 22, 23, 24]]  # ë‘ ë²ˆì§¸ ë°°ì¹˜
])

print("3D Tensor Shape:", tensor_3d.shape)  # (2, 3, 4)

ğŸ“Œ ìƒì„±ëœ í…ì„œ êµ¬ì¡°



ë°°ì¹˜ 0:
[[ 1   2   3   4 ]
 [ 5   6   7   8 ]
 [ 9  10  11  12 ]]

ë°°ì¹˜ 1:
[[13  14  15  16 ]
 [17  18  19  20 ]
 [21  22  23  24 ]]

â¡ Shape: (2, 3, 4)

â¡ (ë°°ì¹˜=2, ë†’ì´=3, ë„ˆë¹„=4)


2. ê° ì°¨ì›ë³„ ì¸ë±ìŠ¤ ìœ„ì¹˜

í…ì„œì—ì„œ íŠ¹ì • ì¸ë±ìŠ¤ì˜ ê°’ì„ ì°¸ì¡°í•  ë•Œ (ë°°ì¹˜, ë†’ì´, ë„ˆë¹„) ìˆœì„œë¡œ ì ‘ê·¼í•©ë‹ˆë‹¤.

ì¸ë±ìŠ¤	ìœ„ì¹˜	ê°’
tensor_3d[0, 0, 0]	ì²« ë²ˆì§¸ ë°°ì¹˜, ì²« ë²ˆì§¸ í–‰, ì²« ë²ˆì§¸ ì—´	1
tensor_3d[0, 0, 1]	ì²« ë²ˆì§¸ ë°°ì¹˜, ì²« ë²ˆì§¸ í–‰, ë‘ ë²ˆì§¸ ì—´	2
tensor_3d[0, 1, 2]	ì²« ë²ˆì§¸ ë°°ì¹˜, ë‘ ë²ˆì§¸ í–‰, ì„¸ ë²ˆì§¸ ì—´	7
tensor_3d[1, 2, 3]	ë‘ ë²ˆì§¸ ë°°ì¹˜, ì„¸ ë²ˆì§¸ í–‰, ë„¤ ë²ˆì§¸ ì—´	24



print("tensor_3d[0, 0, 0]:", tensor_3d[0, 0, 0])  # 1
print("tensor_3d[0, 0, 1]:", tensor_3d[0, 0, 1])  # 2
print("tensor_3d[0, 1, 2]:", tensor_3d[0, 1, 2])  # 7
print("tensor_3d[1, 2, 3]:", tensor_3d[1, 2, 3])  # 24

ğŸ“Œ ì‹¤í–‰ ê²°ê³¼

tensor_3d[0, 0, 0]: tensor(1)
tensor_3d[0, 0, 1]: tensor(2)
tensor_3d[0, 1, 2]: tensor(7)
tensor_3d[1, 2, 3]: tensor(24)

3. íŠ¹ì • ì°¨ì› ì„ íƒí•˜ì—¬ ì¶œë ¥

âœ… (1) íŠ¹ì • ë°°ì¹˜ ì„ íƒ (tensor_3d[0])

print(tensor_3d[0])  # ì²« ë²ˆì§¸ ë°°ì¹˜ ë°ì´í„° ì¶œë ¥

ğŸ“Œ ì‹¤í–‰ ê²°ê³¼


tensor([[ 1,  2,  3,  4],
        [ 5,  6,  7,  8],
        [ 9, 10, 11, 12]])

â¡ ì²« ë²ˆì§¸ ë°°ì¹˜(0ë²ˆì§¸ ì°¨ì›)ê°€ ì¶œë ¥ë¨

âœ… (2) íŠ¹ì • í–‰ ì„ íƒ (tensor_3d[1, 1])

print(tensor_3d[1, 1])  # ë‘ ë²ˆì§¸ ë°°ì¹˜ì˜ ë‘ ë²ˆì§¸ í–‰

ğŸ“Œ ì‹¤í–‰ ê²°ê³¼

tensor([17, 18, 19, 20])

â¡ ë‘ ë²ˆì§¸ ë°°ì¹˜ì—ì„œ ë‘ ë²ˆì§¸ í–‰(1ë²ˆì§¸ í–‰) ì„ íƒë¨

âœ… (3) íŠ¹ì • ì—´ ì„ íƒ (tensor_3d[:, :, 2])

print(tensor_3d[:, :, 2])  # ëª¨ë“  ë°°ì¹˜ì—ì„œ 3ë²ˆì§¸ ì—´ ì„ íƒ

ğŸ“Œ ì‹¤í–‰ ê²°ê³¼


tensor([[ 3,  7, 11],
        [15, 19, 23]])

â¡ ëª¨ë“  ë°°ì¹˜ì—ì„œ 3ë²ˆì§¸ ì—´(ì¸ë±ìŠ¤=2) ê°’ë§Œ ì„ íƒë¨

4. permute()ë¥¼ í™œìš©í•œ ìœ„ì¹˜ ë³€ê²½
âœ… permute(1, 2, 0): (ë°°ì¹˜, ë†’ì´, ë„ˆë¹„) â†’ (ë†’ì´, ë„ˆë¹„, ë°°ì¹˜)


tensor_permuted = tensor_3d.permute(1, 2, 0)  # (ë†’ì´, ë„ˆë¹„, ë°°ì¹˜)
print("Permuted Shape:", tensor_permuted.shape)

ğŸ“Œ ì‹¤í–‰ ê²°ê³¼

Permuted Shape: torch.Size([3, 4, 2])

â¡ ë°°ì¹˜ê°€ ë§ˆì§€ë§‰ìœ¼ë¡œ ì´ë™í•˜ê³ , ë†’ì´ê°€ ì²« ë²ˆì§¸ ì°¨ì›ìœ¼ë¡œ ë³€ê²½ë¨

âœ… permute(2, 0, 1): (ë°°ì¹˜, ë†’ì´, ë„ˆë¹„) â†’ (ë„ˆë¹„, ë°°ì¹˜, ë†’ì´)

tensor_permuted = tensor_3d.permute(2, 0, 1)  # (ë„ˆë¹„, ë°°ì¹˜, ë†’ì´)
print("Permuted Shape:", tensor_permuted.shape)

ğŸ“Œ ì‹¤í–‰ ê²°ê³¼

Permuted Shape: torch.Size([4, 2, 3])

â¡ ë„ˆë¹„ê°€ ì²« ë²ˆì§¸ ì°¨ì›ìœ¼ë¡œ ì´ë™í•˜ê³ , ë°°ì¹˜ì™€ ë†’ì´ì˜ ìˆœì„œë„ ë°”ë€œ

5. ê²°ë¡ 
âœ… 3D í…ì„œëŠ” (ë°°ì¹˜, ë†’ì´, ë„ˆë¹„) = (D_1, D_2, D_3) í˜•íƒœ
âœ… ì¸ë±ì‹±(tensor_3d[i, j, k])ì„ ì‚¬ìš©í•˜ì—¬ íŠ¹ì • ìœ„ì¹˜ ì„ íƒ ê°€ëŠ¥
âœ… permute()ë¥¼ ì‚¬ìš©í•˜ë©´ ì°¨ì›ì˜ ìˆœì„œë¥¼ ë³€ê²½ ê°€ëŠ¥
âœ… íŠ¹ì • ì°¨ì› ì„ íƒ ì‹œ :ë¥¼ í™œìš©í•˜ì—¬ ì „ì²´ ë°°ì¹˜ ë˜ëŠ” íŠ¹ì • í–‰/ì—´ë§Œ ê°€ì ¸ì˜¬ ìˆ˜ ìˆìŒ


=============================================================================
2-5-split() vs chunk() ì°¨ì´ì 

ğŸ“Œ split() vs chunk() ì°¨ì´ì 

torch.split()ê³¼ torch.chunk()ëŠ”

PyTorchì—ì„œ í…ì„œë¥¼ íŠ¹ì • í¬ê¸° ë˜ëŠ” ê°œìˆ˜ë¡œ ë‚˜ëˆ„ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.

ğŸ”¹ 1ï¸ split() í•¨ìˆ˜

split(batch_size, dim) : ì£¼ì–´ì§„ í¬ê¸°(batch_size)ë¡œ í…ì„œë¥¼ ë‚˜ëˆ”.

ë§ˆì§€ë§‰ ë¶€ë¶„ì˜ í¬ê¸°ëŠ” ë‚¨ì€ ìš”ì†Œ ê°œìˆ˜ì— ë”°ë¼ ì¡°ì •ë  ìˆ˜ ìˆìŒ.

ğŸ“Œ ì˜ˆì œ

import torch

x = torch.FloatTensor(10, 4)  # (10, 4) í¬ê¸°ì˜ í…ì„œ ìƒì„±

splits = x.split(4, dim=0)  # ì²« ë²ˆì§¸ ì°¨ì›(í–‰ ê¸°ì¤€)ìœ¼ë¡œ í¬ê¸° 4ì”© ë‚˜ëˆ”

for s in splits:
    print(s.size())

ğŸ“Œ ê²°ê³¼

torch.Size([4, 4])
torch.Size([4, 4])
torch.Size([2, 4])  # ë§ˆì§€ë§‰ ë‚¨ì€ ë¶€ë¶„ (2ê°œ)

ì²« ë²ˆì§¸ì™€ ë‘ ë²ˆì§¸ í…ì„œëŠ” (4, 4), ë§ˆì§€ë§‰ í…ì„œëŠ” (2, 4).

ë§ˆì§€ë§‰ ì¡°ê°ì€ í¬ê¸°ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ. (ì´ 10ê°œ ë°ì´í„°ë¥¼ 4ê°œì”© ë‚˜ëˆ„ë©´ 4+4+2)


ğŸ”¹ 2 ï¸chunk() í•¨ìˆ˜
chunk(n_chunks, dim): ì§€ì •í•œ ê°œìˆ˜(n_chunks)ë¡œ í…ì„œë¥¼ ê· ë“±í•˜ê²Œ ë‚˜ëˆ”.

split()ê³¼ ë‹¤ë¥´ê²Œ í¬ê¸°ê°€ ìë™ìœ¼ë¡œ ê· ë“±í•˜ê²Œ ë°°ë¶„ë¨.

ğŸ“Œ ì˜ˆì œ

x = torch.FloatTensor(8, 4)  # (8, 4) í¬ê¸°ì˜ í…ì„œ ìƒì„±
chunks = x.chunk(3, dim=0)  # 3ê°œë¡œ ë‚˜ëˆ”

for c in chunks:
    print(c.size())

ğŸ“Œ ê²°ê³¼

torch.Size([3, 4])
torch.Size([3, 4])
torch.Size([2, 4])  # ë‚¨ì€ ë¶€ë¶„

split()ê³¼ ìœ ì‚¬í•˜ì§€ë§Œ, ê· ë“±í•˜ê²Œ ë¶„í• í•  ìˆ˜ ìˆë„ë¡ ìë™ìœ¼ë¡œ í¬ê¸°ë¥¼ ë§ì¶¤.

ì²« ë²ˆì§¸, ë‘ ë²ˆì§¸ëŠ” (3, 4), ë§ˆì§€ë§‰ì€ (2, 4).

â†’ 8ì„ 3ìœ¼ë¡œ ë‚˜ëˆ„ë©´ 3+3+2ë¡œ ë‚˜ëˆ ì§.

âœ… split() vs chunk() ë¹„êµ

í•¨ìˆ˜	ë™ì‘ ë°©ì‹	ë§ˆì§€ë§‰ ì¡°ê° í¬ê¸°

split(batch_size, dim)	ì§€ì •ëœ í¬ê¸° batch_sizeë§Œí¼ ë‚˜ëˆ„ê³ 

ë‚¨ì€ ë¶€ë¶„ì„ ë§ˆì§€ë§‰ì— ë°°ì •	ë§ˆì§€ë§‰ ë¶€ë¶„ë§Œ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ

chunk(n_chunks, dim)	ì§€ì •ëœ ê°œìˆ˜ n_chunksë¡œ ê· ë“±í•˜ê²Œ ë¶„í• 
ê· ë“±í•˜ê²Œ ë‚˜ëˆ„ë˜, ë§ˆì§€ë§‰ ì¡°ê°ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ

âœ… ê²°ë¡ 
ì •í™•í•œ í¬ê¸°(batch_size)ë¡œ ë‚˜ëˆ„ë ¤ë©´ split() ì‚¬ìš©.
ê· ë“±í•˜ê²Œ nê°œë¡œ ë‚˜ëˆ„ë ¤ë©´ chunk() ì‚¬ìš©.

=============================================================================
2-6-torch.index_select() í•¨ìˆ˜


PyTorchì˜ index_select() í•¨ìˆ˜ëŠ” íŠ¹ì • ì°¨ì›ì˜ íŠ¹ì • ì¸ë±ìŠ¤ë§Œ ì„ íƒí•˜ì—¬

ìƒˆë¡œìš´ í…ì„œë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.

ğŸ”¹ 1ï¸ index_select() ê¸°ë³¸ ë¬¸ë²•

torch.index_select(input, dim, index)

input : ì›ë³¸ í…ì„œ
dim : ì„ íƒí•  ì°¨ì› (0=í–‰, 1=ì—´, ...)
index : ì„ íƒí•  ì¸ë±ìŠ¤ ë¦¬ìŠ¤íŠ¸
(torch.LongTensor ë˜ëŠ” torch.tensor([...], dtype=torch.long) ì‚¬ìš©)


ğŸ”¹ 2ï¸ í–‰ ì„ íƒ ì˜ˆì œ (dim=0)

import torch

x = torch.arange(12).reshape(4, 3)  # (4,3) í…ì„œ ìƒì„±
print("Original Tensor:\n", x)

# ì„ íƒí•  í–‰ ì¸ë±ìŠ¤ ì •ì˜ (1ë²ˆì§¸, 3ë²ˆì§¸ í–‰ ì„ íƒ)
index = torch.tensor([1, 3], dtype=torch.long)

# í–‰ ì„ íƒ (dim=0)
selected_rows = torch.index_select(x, dim=0, index=index)

print("Selected Rows:\n", selected_rows)


ğŸ“Œ ì¶œë ¥ ê²°ê³¼

Original Tensor:
 tensor([[ 0,  1,  2],
         [ 3,  4,  5],
         [ 6,  7,  8],
         [ 9, 10, 11]])

Selected Rows:
 tensor([[ 3,  4,  5],
         [ 9, 10, 11]])

index=[1,3]ì´ë¯€ë¡œ 1ë²ˆì§¸, 3ë²ˆì§¸ í–‰ë§Œ ì„ íƒë¨.


ğŸ”¹ 3ï¸ ì—´ ì„ íƒ ì˜ˆì œ (dim=1)

index = torch.tensor([0, 2], dtype=torch.long)  # ì²« ë²ˆì§¸, ì„¸ ë²ˆì§¸ ì—´ ì„ íƒ

selected_cols = torch.index_select(x, dim=1, index=index)

print("Selected Columns:\n", selected_cols)

ğŸ“Œ ì¶œë ¥ ê²°ê³¼

Selected Columns:
 tensor([[ 0,  2],
         [ 3,  5],
         [ 6,  8],
         [ 9, 11]])

dim=1 â†’ ì—´ ë°©í–¥ìœ¼ë¡œ ì„ íƒ

index=[0,2]ì´ë¯€ë¡œ ì²« ë²ˆì§¸, ì„¸ ë²ˆì§¸ ì—´ë§Œ ì„ íƒë¨.

ğŸ”¹ 4ï¸ index_select() vs tensor[indices] ì°¨ì´


# ì§ì ‘ ì¸ë±ì‹±
selected_rows = x[[1, 3]]
print(selected_rows)

x[[1, 3]]ì™€ torch.index_select(x, 0, index)ì˜ ì°¨ì´ì 

index_select()ëŠ” ë©”ëª¨ë¦¬ ì—°ì†ì„±ì´ ìœ ì§€ë¨.

x[[...]]ëŠ” ë©”ëª¨ë¦¬ ë¹„ì—°ì†ì ì¸ í…ì„œë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŒ.

âœ… ì •ë¦¬

í•¨ìˆ˜	ê¸°ëŠ¥	ì˜ˆì œ
index_select(x, dim=0, index)
íŠ¹ì • í–‰ ì„ íƒ	index_select(x, 0, torch.tensor([1,3]))

index_select(x, dim=1, index)
íŠ¹ì • ì—´ ì„ íƒ	index_select(x, 1, torch.tensor([0,2]))

x[[indices]]	íŠ¹ì • í–‰ ì„ íƒ (ì§ì ‘ ì¸ë±ì‹±)	x[[1,3]]

âœ… index_select()ëŠ” íŠ¹ì • ì°¨ì›ì˜ ì›í•˜ëŠ” ìš”ì†Œë§Œ ì„ íƒí•  ë•Œ ì‚¬ìš©í•˜ë©´ íš¨ìœ¨ì !

=============================================================================
2-7-torch.cat() (Concatenate) í•¨ìˆ˜

ğŸ“Œ torch.cat() (Concatenate) í•¨ìˆ˜

PyTorchì˜ torch.cat() í•¨ìˆ˜ëŠ” ì—¬ëŸ¬ ê°œì˜ í…ì„œë¥¼
íŠ¹ì • ì°¨ì›(dim)ìœ¼ë¡œ ì—°ê²°(Concatenate)í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.


ğŸ”¹ 1ï¸ torch.cat() ê¸°ë³¸ ë¬¸ë²•

torch.cat(tensors, dim)
tensors : ì—°ê²°í•  í…ì„œë“¤ì˜ ë¦¬ìŠ¤íŠ¸ [tensor1, tensor2, ...]
dim : ì—°ê²°í•  ì°¨ì› (0=í–‰ ë°©í–¥, 1=ì—´ ë°©í–¥, ...)


ğŸ”¹ 2ï¸ í–‰ ë°©í–¥(dim=0)ìœ¼ë¡œ ì—°ê²°

import torch

a = torch.tensor([[1, 2], [3, 4]])  # (2,2)
b = torch.tensor([[5, 6], [7, 8]])  # (2,2)

# í–‰ ë°©í–¥(dim=0)ìœ¼ë¡œ ì—°ê²°
c = torch.cat([a, b], dim=0)

print("Concatenated Tensor (dim=0):\n", c)
print("Shape:", c.shape)

ğŸ“Œ ì¶œë ¥ ê²°ê³¼

Concatenated Tensor (dim=0):
 tensor([[1, 2],
         [3, 4],
         [5, 6],
         [7, 8]])

Shape: torch.Size([4, 2])

(2,2) + (2,2) â†’ (4,2)

í–‰ì´ ëŠ˜ì–´ë‚¨(ìˆ˜ì§ ë°©í–¥ìœ¼ë¡œ ì—°ê²°).


ğŸ”¹ 3ï¸ ì—´ ë°©í–¥(dim=1)ìœ¼ë¡œ ì—°ê²°

c = torch.cat([a, b], dim=1)  # ì—´ ë°©í–¥ìœ¼ë¡œ ì—°ê²°

print("Concatenated Tensor (dim=1):\n", c)
print("Shape:", c.shape)


ğŸ“Œ ì¶œë ¥ ê²°ê³¼

Concatenated Tensor (dim=1):
 tensor([[1, 2, 5, 6],
         [3, 4, 7, 8]])

Shape: torch.Size([2, 4])
(2,2) + (2,2) â†’ (2,4)

ì—´ì´ ëŠ˜ì–´ë‚¨(ìˆ˜í‰ ë°©í–¥ìœ¼ë¡œ ì—°ê²°).

ğŸ”¹ 4ï¸ cat()ì„ ì‚¬ìš©í•  ë•Œ ì£¼ì˜í•  ì 

âœ”ï¸ ì°¨ì›ì´ ë™ì¼í•´ì•¼ í•¨

ì—°ê²°í•  í…ì„œëŠ” ëª¨ë“  ì°¨ì›ì´ ë™ì¼í•´ì•¼ í•˜ë©°, dim ë°©í–¥ë§Œ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ.

ì˜ˆì œì—ì„œ (2,2) í¬ê¸°ì˜ a, bë¥¼ dim=0ìœ¼ë¡œ ì—°ê²°í•˜ë©´ í–‰ ê°œìˆ˜ê°€ ì¦ê°€í•˜ê³  (4,2)ì´ ë¨.

ì˜¤ë¥˜ ì˜ˆì œ

a = torch.tensor([[1, 2]])  # (1,2)
b = torch.tensor([[3], [4]])  # (2,1)

c = torch.cat([a, b], dim=0)  # ì„œë¡œ ë‹¤ë¥¸ shape â†’ ì˜¤ë¥˜ ë°œìƒ!

ğŸ”´ ì˜¤ë¥˜ ë°œìƒ

RuntimeError: Sizes of tensors must match except in dimension 0
í•´ê²° ë°©ë²•: reshape() ë˜ëŠ” unsqueeze()ë¥¼ ì‚¬ìš©í•˜ì—¬ í¬ê¸°ë¥¼ ë§ì¶°ì•¼ í•¨.

âœ… ì •ë¦¬
í•¨ìˆ˜	ê¸°ëŠ¥	ê²°ê³¼
torch.cat([a, b], dim=0)	í–‰(ìˆ˜ì§)ìœ¼ë¡œ ì—°ê²°	(2,2) + (2,2) â†’ (4,2)
torch.cat([a, b], dim=1)	ì—´(ìˆ˜í‰)ìœ¼ë¡œ ì—°ê²°	(2,2) + (2,2) â†’ (2,4)

âœ… torch.cat()ì€ ë°ì´í„° í•©ì¹˜ê¸°, ë°°ì¹˜ ë°ì´í„° ë³‘í•© ë“±ì— ìœ ìš©!

=============================================================================
2-8-torch.stack() í•¨ìˆ˜


PyTorchì˜ torch.stack() í•¨ìˆ˜ëŠ”

ìƒˆë¡œìš´ ì°¨ì›ì„ ì¶”ê°€í•˜ë©´ì„œ ì—¬ëŸ¬ í…ì„œë¥¼ ìŒ“ëŠ”(stack) í•¨ìˆ˜ì…ë‹ˆë‹¤.

ğŸ”¹ 1ï¸ torch.stack() ê¸°ë³¸ ë¬¸ë²•

torch.stack(tensors, dim)
tensors : ìŠ¤íƒí•  í…ì„œë“¤ì˜ ë¦¬ìŠ¤íŠ¸ [tensor1, tensor2, ...]
dim : ìƒˆë¡œìš´ ì°¨ì›ì„ ì¶”ê°€í•  ìœ„ì¹˜

âœ… cat()ê³¼ì˜ ì°¨ì´ì :

cat()ì€ ê¸°ì¡´ ì°¨ì›ì—ì„œ ì—°ê²° (ìƒˆë¡œìš´ ì°¨ì› ì¶”ê°€ âŒ).

stack()ì€ ìƒˆë¡œìš´ ì°¨ì› ì¶”ê°€í•˜ë©´ì„œ ì—°ê²° (ìƒˆë¡œìš´ ì°¨ì› ì¶”ê°€ â­•).


ğŸ”¹ 2ï¸ stack() ì˜ˆì œ

ğŸ“Œ ì˜ˆì œ 1: ê¸°ë³¸ ì‚¬ìš© (dim=0)

import torch

a = torch.tensor([1, 2, 3])  # (3,)
b = torch.tensor([4, 5, 6])  # (3,)

c = torch.stack([a, b], dim=0)  # ìƒˆë¡œìš´ ì°¨ì› ì¶”ê°€

print("Stacked Tensor (dim=0):\n", c)
print("Shape:", c.shape)

ğŸ“Œ ì¶œë ¥ ê²°ê³¼

Stacked Tensor (dim=0):
 tensor([[1, 2, 3],
         [4, 5, 6]])

Shape: torch.Size([2, 3])

ìƒˆë¡œìš´ ì°¨ì›ì´ 0ë²ˆ(dim=0) ìœ„ì¹˜ì— ì¶”ê°€ë¨.

ê²°ê³¼ shape: (2,3)
â†’ ê¸°ì¡´ (3,) í…ì„œ 2ê°œë¥¼ ìŒ“ì•„ì„œ (2,3) í…ì„œ ìƒì„±.


ğŸ“Œ ì˜ˆì œ 2: dim=1ì¼ ë•Œ

c = torch.stack([a, b], dim=1)  # ìƒˆë¡œìš´ ì°¨ì›ì„ 1ë²ˆ ìœ„ì¹˜ì— ì¶”ê°€

print("Stacked Tensor (dim=1):\n", c)
print("Shape:", c.shape)

ğŸ“Œ ì¶œë ¥ ê²°ê³¼


Stacked Tensor (dim=1):
 tensor([[1, 4],
         [2, 5],
         [3, 6]])

Shape: torch.Size([3, 2])

ìƒˆë¡œìš´ ì°¨ì›ì´ 1ë²ˆ(dim=1) ìœ„ì¹˜ì— ì¶”ê°€ë¨.
ê²°ê³¼ shape: (3,2) â†’ ê¸°ì¡´ (3,) í…ì„œ 2ê°œë¥¼ (3,2) í˜•íƒœë¡œ ë³€í™˜.

ğŸ“Œ ì˜ˆì œ 3: 2D í…ì„œì— ì ìš©

a = torch.tensor([[1, 2], [3, 4]])  # (2,2)
b = torch.tensor([[5, 6], [7, 8]])  # (2,2)

c = torch.stack([a, b], dim=0)
print("Stacked Tensor (dim=0):\n", c)
print("Shape:", c.shape)

ğŸ“Œ ì¶œë ¥ ê²°ê³¼

Stacked Tensor (dim=0):
 tensor([[[1, 2],
          [3, 4]],

         [[5, 6],
          [7, 8]]])
Shape: torch.Size([2, 2, 2])

dim=0ìœ¼ë¡œ stackí•˜ë©´ (2,2) â†’ (2,2,2) (ìƒˆë¡œìš´ ì°¨ì› ì¶”ê°€ë¨)

âœ… ì •ë¦¬
í•¨ìˆ˜	ê¸°ëŠ¥	ê²°ê³¼ ì˜ˆì‹œ
torch.stack([a, b], dim=0)	ìƒˆë¡œìš´ ì°¨ì›ì„ ì¶”ê°€í•˜ë©° ìŒ“ìŒ	(3,) â†’ (2,3)
torch.stack([a, b], dim=1)	ì—´ ë°©í–¥ìœ¼ë¡œ ì°¨ì› ì¶”ê°€	(3,) â†’ (3,2)
torch.cat([a, b], dim=0)	ê¸°ì¡´ ì°¨ì›ì—ì„œ ì—°ê²°	(3,) + (3,) â†’ (6,)

ğŸš€ stack()ì€ ìƒˆë¡œìš´ ì°¨ì›ì´ í•„ìš”í•  ë•Œ ì‚¬ìš©! (cat()ê³¼ ì°¨ì´ì  ì£¼ì˜) ğŸ¯


ğŸ“Œ 2D í…ì„œì— stack(dim=1) ì ìš© ì˜ˆì œ


import torch

# 2D í…ì„œ ìƒì„± (2x2 í¬ê¸°)
a = torch.tensor([[1, 2], [3, 4]])  # Shape: (2,2)
b = torch.tensor([[5, 6], [7, 8]])  # Shape: (2,2)

# dim=1 ë°©í–¥ìœ¼ë¡œ stack ì ìš©
c = torch.stack([a, b], dim=1)

# ê²°ê³¼ ì¶œë ¥
print("Stacked Tensor (dim=1):\n", c)
print("Shape:", c.shape)


a = torch.tensor([[1, 2], [3, 4]])  # Shape: (2,2)

(2,1,2)
[
 [      # 0 ë°°ì¹˜
 [1,2]
 ],

 [      # 1 ë°°ì¹˜
 [3,4]
 ],

]

ì¶”ê°€, dim=1 , ê²°êµ­ í–‰ë°©í–¥

[
 [      # 0 ë°°ì¹˜
 [1,2],
 [5,6]
 ],

 [      # 1 ë°°ì¹˜
 [3,4],
 [7,8]
 ],

]

ğŸ“Œ ì˜ˆìƒ ì¶œë ¥ ê²°ê³¼


Stacked Tensor (dim=1):
 tensor([[[1, 2],
          [5, 6]],

         [[3, 4],
          [7, 8]]])

Shape: torch.Size([2, 2, 2])

dim=1ì— ìƒˆë¡œìš´ ì°¨ì›ì„ ì¶”ê°€í•˜ë©´ì„œ ìŒ“ì˜€ê¸° ë•Œë¬¸ì— (2,2,2) í¬ê¸°ì˜ í…ì„œê°€ ìƒì„±ë¨.

(2,2) â†’ (2,2,2) í˜•íƒœë¡œ ë³€í™˜.

=============================================================================
2-9-expand() ì˜ˆì œ


import torch

# 3D í…ì„œ ìƒì„± (2, 1, 2)
x = torch.FloatTensor([[[1, 2]], [[3, 4]]])
print("Original x shape:", x.shape)

# expand()ë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒˆë¡œìš´ ì°¨ì› í™•ì¥ (2, 3, 2)
y = x.expand(2, 3, 2)

# ê²°ê³¼ ì¶œë ¥
print("Expanded y shape:", y.shape)

print("Expanded y Tensor:\n", y)

ğŸ“Œ ì˜ˆìƒ ì¶œë ¥ ê²°ê³¼

Original x shape: torch.Size([2, 1, 2])
Expanded y shape: torch.Size([2, 3, 2])
Expanded y Tensor:
 tensor([[[1., 2.],
          [1., 2.],
          [1., 2.]],

         [[3., 4.],
          [3., 4.],
          [3., 4.]]])
ğŸ”¹ ì„¤ëª…
ì›ë³¸ í…ì„œ xì˜ í¬ê¸°: (2, 1, 2)

2: ë°°ì¹˜ í¬ê¸°
1: í™•ì¥ë  ì°¨ì› (ë‹¨ì¼ ì°¨ì›)
2: ì»¬ëŸ¼ ê°œìˆ˜
expand(2, 3, 2) ì ìš© í›„

dim=1ì—ì„œ 1 â†’ 3ìœ¼ë¡œ í™•ì¥ë¨.
ë©”ëª¨ë¦¬ ì¬í• ë‹¹ ì—†ì´ ê¸°ì¡´ ê°’ì„ ë°˜ë³µí•˜ì—¬ í™•ì¥ (Broadcasting).

âœ… ì£¼ì˜í•  ì 
expand()ëŠ” ë©”ëª¨ë¦¬   ì—†ì´ ê¸°ì¡´ í…ì„œë¥¼ í™•ì¥í•˜ë©°, ì‹¤ì œë¡œëŠ” ë·°(View) ë¥¼ ì œê³µ.
ë³€ê²½ ë¶ˆê°€ëŠ¥(Immutable) â†’ expand()í•œ í…ì„œì—ì„œ ê°’ì„ ì§ì ‘ ìˆ˜ì •í•  ìˆ˜ ì—†ìŒ.
ë©”ëª¨ë¦¬ ì—°ì†ì„± í•„ìš”í•  ê²½ìš° clone() ì‚¬ìš©:


y_clone = y.clone()

âœ… expand()ëŠ” ë¸Œë¡œë“œìºìŠ¤íŒ…(Broadcasting)ì„ í™œìš©í•œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ì—°ì‚°ì— ìœ ìš©

=============================================================================
2-10-torch.randperm() ì˜ˆì œ


import torch

# 0ë¶€í„° 9ê¹Œì§€ì˜ ìˆ«ìë¥¼ ë¬´ì‘ìœ„ë¡œ ì„ê¸° (ìˆœì—´ ìƒì„±)
perm = torch.randperm(10)

# ê²°ê³¼ ì¶œë ¥
print("Random Permutation:", perm)

ğŸ“Œ ì˜ˆìƒ ì¶œë ¥ ê²°ê³¼

Random Permutation: tensor([2, 5, 8, 1, 3, 7, 4, 6, 0, 9])

torch.randperm(n)ì€ 0ë¶€í„° n-1ê¹Œì§€ì˜ ìˆ«ìë¥¼ ëœë¤í•œ ìˆœì„œë¡œ ì •ë ¬í•œ í…ì„œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

**ìˆœì—´(Permutation)**ì„ ìƒì„±í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.

ğŸ”¹ ì‘ìš© ì˜ˆì œ
âœ… ë°ì´í„°ì…‹ì˜ ì¸ë±ìŠ¤ ëœë¤ ì„ê¸°

data = torch.tensor([10, 20, 30, 40, 50])
indices = torch.randperm(len(data))

shuffled_data = data[indices]

print("Original Data:", data)
print("Shuffled Data:", shuffled_data)

ğŸ“Œ ì˜ˆìƒ ì¶œë ¥ ê²°ê³¼

Original Data: tensor([10, 20, 30, 40, 50])
Shuffled Data: tensor([30, 10, 50, 20, 40])  # ë¬´ì‘ìœ„ ìˆœì„œ
torch.randperm()ì„ í™œìš©í•˜ì—¬ ë°ì´í„°ë¥¼ ëœë¤í•˜ê²Œ ì„ì„ ë•Œ ìœ ìš©í•©ë‹ˆë‹¤.

âœ… ì •ë¦¬

í•¨ìˆ˜	ê¸°ëŠ¥
torch.randperm(n)	0ë¶€í„° n-1ê¹Œì§€ì˜ ëœë¤ ìˆœì—´ ìƒì„±
data[torch.randperm(len(data))]	ë°ì´í„° ë¬´ì‘ìœ„ ì„ê¸°

âœ… torch.randperm()ì€ ë°ì´í„° ìˆœì„œë¥¼ ë¬´ì‘ìœ„ë¡œ ë°”ê¿€ ë•Œ ìœ ìš©í•œ í•¨ìˆ˜!

=============================================================================
2-11-torch.argmax(dim=n) ì˜ˆì œ



import torch

# 3x3 í…ì„œ ìƒì„±
x = torch.tensor([[1, 7, 3],
                  [4, 2, 9],
                  [8, 6, 5]])

# argmax(dim=0): ì—´ ë°©í–¥(ì„¸ë¡œ)ì—ì„œ ìµœëŒ€ê°’ì˜ ì¸ë±ìŠ¤ ì°¾ê¸°

argmax_dim0 = torch.argmax(x, dim=0)

# argmax(dim=1): í–‰ ë°©í–¥(ê°€ë¡œ)ì—ì„œ ìµœëŒ€ê°’ì˜ ì¸ë±ìŠ¤ ì°¾ê¸°

argmax_dim1 = torch.argmax(x, dim=1)

# ê²°ê³¼ ì¶œë ¥
print("Tensor:\n", x)
print("\nArgmax along dim=0 (column-wise):", argmax_dim0)
print("Argmax along dim=1 (row-wise):", argmax_dim1)

ğŸ“Œ ì˜ˆìƒ ì¶œë ¥ ê²°ê³¼

Tensor:
 tensor([[1, 7, 3],
         [4, 2, 9],
         [8, 6, 5]])

Argmax along dim=0 (column-wise): tensor([2, 0, 1])
Argmax along dim=1 (row-wise): tensor([1, 2, 0])

ğŸ”¹ ì„¤ëª…
torch.argmax(x, dim=0) â†’ ì—´ ë°©í–¥ (dim=0)ì—ì„œ ìµœëŒ€ê°’ì˜ ì¸ë±ìŠ¤ ë°˜í™˜

ì²« ë²ˆì§¸ ì—´ [1, 4, 8] â†’ ìµœëŒ€ê°’: 8 (ì¸ë±ìŠ¤ 2)
ë‘ ë²ˆì§¸ ì—´ [7, 2, 6] â†’ ìµœëŒ€ê°’: 7 (ì¸ë±ìŠ¤ 0)
ì„¸ ë²ˆì§¸ ì—´ [3, 9, 5] â†’ ìµœëŒ€ê°’: 9 (ì¸ë±ìŠ¤ 1)

ê²°ê³¼: tensor([2, 0, 1])

torch.argmax(x, dim=1) â†’ í–‰ ë°©í–¥ (dim=1)ì—ì„œ ìµœëŒ€ê°’ì˜ ì¸ë±ìŠ¤ ë°˜í™˜

ì²« ë²ˆì§¸ í–‰ [1, 7, 3] â†’ ìµœëŒ€ê°’: 7 (ì¸ë±ìŠ¤ 1)
ë‘ ë²ˆì§¸ í–‰ [4, 2, 9] â†’ ìµœëŒ€ê°’: 9 (ì¸ë±ìŠ¤ 2)
ì„¸ ë²ˆì§¸ í–‰ [8, 6, 5] â†’ ìµœëŒ€ê°’: 8 (ì¸ë±ìŠ¤ 0)

ê²°ê³¼: tensor([1, 2, 0])

âœ… ì •ë¦¬
ì—°ì‚°	ì„¤ëª…	ê²°ê³¼ ì˜ˆì‹œ

torch.argmax(x, dim=0)	ì—´ ë°©í–¥(ì„¸ë¡œ)ì—ì„œ ìµœëŒ€ê°’ì˜ ì¸ë±ìŠ¤ ë°˜í™˜
tensor([2, 0, 1])
torch.argmax(x, dim=1)	í–‰ ë°©í–¥(ê°€ë¡œ)ì—ì„œ ìµœëŒ€ê°’ì˜ ì¸ë±ìŠ¤ ë°˜í™˜
tensor([1, 2, 0])

âœ… torch.argmax(dim=n)ì„ ì‚¬ìš©í•˜ë©´ íŠ¹ì • ì°¨ì›ì—ì„œ
ìµœëŒ€ê°’ì˜ ì¸ë±ìŠ¤ë¥¼ ì‰½ê²Œ ì°¾ì„ ìˆ˜ ìˆìŒ!

=============================================================================
2-12-torch.topk() ì˜ˆì œ


import torch

# 3x3 í…ì„œ ìƒì„±
x = torch.tensor([[1, 7, 3],
                  [4, 2, 9],
                  [8, 6, 5]])

# ê° í–‰(row)ì—ì„œ ìµœëŒ€ê°’ 1ê°œ(`k=1`) ì°¾ê¸° (dim=-1 â†’ ë§ˆì§€ë§‰ ì°¨ì› ê¸°ì¤€)

topk_values, topk_indices = torch.topk(x, k=1, dim=-1)

# ê²°ê³¼ ì¶œë ¥
print("Tensor:\n", x)
print("\nTop-1 values along dim=-1 (row-wise):", topk_values)
print("Top-1 indices along dim=-1:", topk_indices)

ğŸ“Œ ì˜ˆìƒ ì¶œë ¥ ê²°ê³¼


Tensor:
 tensor([[1, 7, 3],
         [4, 2, 9],
         [8, 6, 5]])

Top-1 values along dim=-1 (row-wise): tensor([[7],
                                             [9],
                                             [8]])

Top-1 indices along dim=-1: tensor([[1],
                                    [2],
                                    [0]])
ğŸ”¹ ì„¤ëª…
torch.topk(x, k=1, dim=-1)
dim=-1ì€ ë§ˆì§€ë§‰ ì°¨ì›(ì—¬ê¸°ì„œëŠ” í–‰ ë°©í–¥)ì„ ê¸°ì¤€ìœ¼ë¡œ ë™ì‘.

k=1ì´ë¯€ë¡œ ê° í–‰(row)ì—ì„œ ê°€ì¥ í° ê°’ 1ê°œë¥¼ ì„ íƒ.

topk_values: ê° í–‰ì—ì„œ ìµœëŒ€ê°’ ë°˜í™˜.
topk_indices: ê° í–‰ì—ì„œ ìµœëŒ€ê°’ì˜ ì¸ë±ìŠ¤ ë°˜í™˜.

ğŸ“Œ ê²°ê³¼ í•´ì„
ì²« ë²ˆì§¸ í–‰ [1, 7, 3] â†’ ìµœëŒ€ê°’: 7 (ì¸ë±ìŠ¤ 1)
ë‘ ë²ˆì§¸ í–‰ [4, 2, 9] â†’ ìµœëŒ€ê°’: 9 (ì¸ë±ìŠ¤ 2)
ì„¸ ë²ˆì§¸ í–‰ [8, 6, 5] â†’ ìµœëŒ€ê°’: 8 (ì¸ë±ìŠ¤ 0)

âœ… ì •ë¦¬
ì—°ì‚°	ì„¤ëª…	ê²°ê³¼ ì˜ˆì‹œ
torch.topk(x, k=1, dim=0)
ì—´ ë°©í–¥ì—ì„œ ìµœëŒ“ê°’ 1ê°œ ì„ íƒ	tensor([[8, 7, 9]])

torch.topk(x, k=1, dim=1)
í–‰ ë°©í–¥ì—ì„œ ìµœëŒ“ê°’ 1ê°œ ì„ íƒ	tensor([[7], [9], [8]])

âœ… torch.topk()ë¥¼ ì‚¬ìš©í•˜ë©´ kê°œì˜ ìµœëŒ“ê°’ê³¼ í•´ë‹¹ ì¸ë±ìŠ¤ë¥¼ ì‰½ê²Œ ì°¾ì„ ìˆ˜ ìˆìŒ!


ğŸ“Œ torch.topk(x, k=x.size(target_dim), largest=True) ì˜µì…˜ ì„¤ëª…
torch.topk(x, k, dim, largest=True/False)

k=x.size(target_dim) â†’ ì„ íƒëœ ì°¨ì›ì˜ ëª¨ë“  ì›ì†Œë¥¼ ë°˜í™˜ (ì •ë ¬ íš¨ê³¼).

k = x.size(1)ì˜ ê°’ì€ 3ì…ë‹ˆë‹¤.

ğŸ”¹ í•´ì„
x.size(1)ì€ x í…ì„œì˜ ë‘ ë²ˆì§¸ ì°¨ì›(ì—´ ê°œìˆ˜)ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
xëŠ” (3,3) í¬ê¸°ì˜ í…ì„œì´ë¯€ë¡œ x.size(1) = 3ì…ë‹ˆë‹¤.
ë”°ë¼ì„œ torch.topk()ì—ì„œ k=3ì„ ì„¤ì •í•˜ë©´,
ê° í–‰ì—ì„œ 3ê°œì˜ ìµœëŒ“ê°’ì„ ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì •ë ¬í•©ë‹ˆë‹¤. â€‹

largest=True â†’ ë‚´ë¦¼ì°¨ìˆœ(í° ê°’ë¶€í„° ì •ë ¬).
largest=False â†’ ì˜¤ë¦„ì°¨ìˆœ(ì‘ì€ ê°’ë¶€í„° ì •ë ¬).

ğŸ”¹ 1ï¸ ì˜ˆì œ ì½”ë“œ



import torch

# 3x3 í…ì„œ ìƒì„±
x = torch.tensor([[1, 7, 3],
                  [4, 2, 9],
                  [8, 6, 5]])

# í–‰(dim=1) ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ë‚´ë¦¼ì°¨ìˆœ)
sorted_values, sorted_indices = torch.topk(x, k=x.size(1), dim=1, largest=True)

# ê²°ê³¼ ì¶œë ¥
print("Tensor:\n", x)
print("\nSorted values (descending order):\n", sorted_values)
print("Sorted indices:\n", sorted_indices)

ğŸ“Œ ì˜ˆìƒ ì¶œë ¥ ê²°ê³¼

Tensor:
 tensor([[1, 7, 3],
         [4, 2, 9],
         [8, 6, 5]])

Sorted values (descending order):
 tensor([[7, 3, 1],
         [9, 4, 2],
         [8, 6, 5]])

Sorted indices:
 tensor([[1, 2, 0],
         [2, 0, 1],
         [0, 1, 2]])


ğŸ”¹ 2ï¸ largest=False (ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬)


sorted_values_asc, sorted_indices_asc = torch.topk(x, k=x.size(1), dim=1, largest=False)

print("\nSorted values (ascending order):\n", sorted_values_asc)
print("Sorted indices:\n", sorted_indices_asc)

ğŸ“Œ ì˜ˆìƒ ì¶œë ¥ ê²°ê³¼

Sorted values (ascending order):
 tensor([[1, 3, 7],
         [2, 4, 9],
         [5, 6, 8]])

Sorted indices:
 tensor([[0, 2, 1],
         [1, 0, 2],
         [2, 1, 0]])

âœ… ì •ë¦¬
ì˜µì…˜	ë™ì‘	ê²°ê³¼
largest=True	í° ê°’ë¶€í„° ì •ë ¬	ë‚´ë¦¼ì°¨ìˆœ (ìµœëŒ“ê°’ì´ ë¨¼ì €)
largest=False	ì‘ì€ ê°’ë¶€í„° ì •ë ¬	ì˜¤ë¦„ì°¨ìˆœ (ìµœì†Ÿê°’ì´ ë¨¼ì €)
k=x.size(dim)	ì „ì²´ ì •ë ¬ íš¨ê³¼	ì™„ì „íˆ ì •ë ¬ëœ ê²°ê³¼

âœ… torch.topk(x, k=x.size(dim), dim, largest=True/False)ë¥¼ ì‚¬ìš©í•˜ë©´ ì •ë ¬ íš¨ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŒ! ğŸš€

=============================================================================
2-13-masked_fill() ì˜ˆì œ

import torch

# 3x3 í…ì„œ ìƒì„±
x = torch.tensor([[1, 7, 3],
                  [4, 2, 9],
                  [8, 6, 5]])

# ë§ˆìŠ¤í¬ ìƒì„± (Trueì¸ ìœ„ì¹˜ì— -1ì„ ì±„ìš¸ ê²ƒ)
mask = x > 5  # ê°’ì´ 5ë³´ë‹¤ í° ê²½ìš° True

# masked_fill ì ìš©
x_masked = x.masked_fill(mask, value=-1)

# ê²°ê³¼ ì¶œë ¥
print("Original Tensor:\n", x)
print("\nMask:\n", mask)
print("\nMasked Tensor:\n", x_masked)


ğŸ“Œ ì˜ˆìƒ ì¶œë ¥ ê²°ê³¼

Original Tensor:
 tensor([[1, 7, 3],
         [4, 2, 9],
         [8, 6, 5]])

Mask:
 tensor([[False,  True, False],
         [False, False,  True],
         [ True,  True, False]])

Masked Tensor:
 tensor([[ 1, -1,  3],
         [ 4,  2, -1],
         [-1, -1,  5]])
ğŸ”¹ ì„¤ëª…
mask = x > 5
Trueê°€ ë˜ëŠ” ìœ„ì¹˜ëŠ” x ê°’ì´ 5ë³´ë‹¤ í° ê²½ìš°.
x.masked_fill(mask, value=-1)
mask=Trueì¸ ìœ„ì¹˜ë¥¼ -1ë¡œ ë³€ê²½.
ğŸ“Œ mask ê²°ê³¼



tensor([[False,  True, False],
        [False, False,  True],
        [ True,  True, False]])
â†’ 7, 9, 8, 6ì´ ìˆëŠ” ìœ„ì¹˜ê°€ True.

ğŸ“Œ masked_fill() ê²°ê³¼



tensor([[ 1, -1,  3],
        [ 4,  2, -1],
        [-1, -1,  5]])
â†’ 7, 9, 8, 6ì„ -1ë¡œ ë³€ê²½.

âœ… ì •ë¦¬

í•¨ìˆ˜	ê¸°ëŠ¥
x.masked_fill(mask, value=-1)	mask=Trueì¸ ìœ„ì¹˜ë¥¼ -1ë¡œ ë³€ê²½
mask = x > 5	5ë³´ë‹¤ í° ê°’ì˜ ìœ„ì¹˜ë¥¼ Trueë¡œ ì„¤ì •
mask = x == 3	íŠ¹ì • ê°’(ì˜ˆ: 3)ì˜ ìœ„ì¹˜ë¥¼ Trueë¡œ ì„¤ì •

âœ… masked_fill()ì„ ì‚¬ìš©í•˜ë©´ íŠ¹ì • ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ê°’ì„ ì‰½ê²Œ ë³€ê²½í•  ìˆ˜ ìˆìŒ!

=============================================================================
2-14-ones(), zeros(), ones_like(), zeros_like() ì˜ˆì œ



import torch

# 1ï¸ ones() - 3x3 í¬ê¸°ì˜ 1ë¡œ ì±„ì›Œì§„ í…ì„œ ìƒì„±
ones_tensor = torch.ones(3, 3)

# 2ï¸ zeros() - 3x3 í¬ê¸°ì˜ 0ìœ¼ë¡œ ì±„ì›Œì§„ í…ì„œ ìƒì„±
zeros_tensor = torch.zeros(3, 3)

# 3ï¸ ones_like() - ê¸°ì¡´ í…ì„œì™€ ê°™ì€ í¬ê¸°ì˜ 1ë¡œ ì±„ì›Œì§„ í…ì„œ ìƒì„±
x = torch.tensor([[2, 3, 4], [5, 6, 7]])  # (2,3) í¬ê¸° í…ì„œ
ones_like_tensor = torch.ones_like(x)

# 4ï¸ zeros_like() - ê¸°ì¡´ í…ì„œì™€ ê°™ì€ í¬ê¸°ì˜ 0ìœ¼ë¡œ ì±„ì›Œì§„ í…ì„œ ìƒì„±
zeros_like_tensor = torch.zeros_like(x)

# ê²°ê³¼ ì¶œë ¥
print("ones():\n", ones_tensor)
print("\nzeros():\n", zeros_tensor)
print("\nones_like(x):\n", ones_like_tensor)
print("\nzeros_like(x):\n", zeros_like_tensor)

ğŸ“Œ ì˜ˆìƒ ì¶œë ¥ ê²°ê³¼



ones():
 tensor([[1., 1., 1.],
         [1., 1., 1.],
         [1., 1., 1.]])

zeros():
 tensor([[0., 0., 0.],
         [0., 0., 0.],
         [0., 0., 0.]])

ones_like(x):
 tensor([[1, 1, 1],
         [1, 1, 1]])

zeros_like(x):
 tensor([[0, 0, 0],
         [0, 0, 0]])

ğŸ”¹ ì„¤ëª…
âœ… torch.ones(size)
ì§€ì •í•œ sizeë§Œí¼ 1ë¡œ ì±„ì›Œì§„ í…ì„œ ìƒì„±.
ì˜ˆ: torch.ones(3,3) â†’ (3,3) í¬ê¸°ì˜ 1ë¡œ ì±„ì›Œì§„ í…ì„œ.

âœ… torch.zeros(size)
ì§€ì •í•œ sizeë§Œí¼ 0ìœ¼ë¡œ ì±„ì›Œì§„ í…ì„œ ìƒì„±.
ì˜ˆ: torch.zeros(3,3) â†’ (3,3) í¬ê¸°ì˜ 0ìœ¼ë¡œ ì±„ì›Œì§„ í…ì„œ.

âœ… torch.ones_like(tensor)
ì£¼ì–´ì§„ tensorì™€ ê°™ì€ í¬ê¸°ì˜ 1ë¡œ ì±„ì›Œì§„ í…ì„œ ìƒì„±.
ì˜ˆ: torch.ones_like(x) â†’ xì™€ ê°™ì€ í¬ê¸°ì˜ 1ë¡œ ì±„ì›Œì§„ í…ì„œ.

âœ… torch.zeros_like(tensor)
ì£¼ì–´ì§„ tensorì™€ ê°™ì€ í¬ê¸°ì˜ 0ìœ¼ë¡œ ì±„ì›Œì§„ í…ì„œ ìƒì„±.
ì˜ˆ: torch.zeros_like(x) â†’ xì™€ ê°™ì€ í¬ê¸°ì˜ 0ìœ¼ë¡œ ì±„ì›Œì§„ í…ì„œ.

âœ… ì •ë¦¬
í•¨ìˆ˜	ê¸°ëŠ¥	ì˜ˆì œ ê²°ê³¼ ((2,3))
torch.ones(2,3)	(2,3) í¬ê¸°ì˜ 1ë¡œ ì±„ìš´ í…ì„œ ìƒì„±	[[1,1,1], [1,1,1]]
torch.zeros(2,3)	(2,3) í¬ê¸°ì˜ 0ìœ¼ë¡œ ì±„ìš´ í…ì„œ ìƒì„±	[[0,0,0], [0,0,0]]
torch.ones_like(x)	xì™€ ê°™ì€ í¬ê¸°ì˜ 1ë¡œ ì±„ìš´ í…ì„œ ìƒì„±	[[1,1,1], [1,1,1]]
torch.zeros_like(x)	xì™€ ê°™ì€ í¬ê¸°ì˜ 0ìœ¼ë¡œ ì±„ìš´ í…ì„œ ìƒì„±	[[0,0,0], [0,0,0]]

=============================================================================





























